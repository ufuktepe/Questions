https
//en.wikipedia.org/wiki/probability
probability
numerical
description
likely
event
occur
likely
proposition
true
probability
number
0
1
roughly
speaking
0
indicates
impossibility
1
indicates
certainty
higher
probability
event
likely
event
occur
simple
example
tossing
fair
unbiased
coin
since
coin
fair
two
outcomes
``
heads
''
``
tails
''
equally
probable
probability
``
heads
''
equals
probability
``
tails
''
since
outcomes
possible
probability
either
``
heads
''
``
tails
''
1/2
could
also
written
0.5
50
concepts
given
axiomatic
mathematical
formalization
probability
theory
used
widely
areas
study
mathematics
statistics
finance
gambling
science
particular
physics
artificial
intelligence/machine
learning
computer
science
game
theory
philosophy
example
draw
inferences
expected
frequency
events
probability
theory
also
used
describe
underlying
mechanics
regularities
complex
systems
==
interpretations
==
dealing
experiments
random
well-defined
purely
theoretical
setting
like
tossing
fair
coin
probabilities
numerically
described
number
desired
outcomes
divided
total
number
outcomes
example
tossing
fair
coin
twice
yield
``
head-head
''
``
head-tail
''
``
tail-head
''
``
tail-tail
''
outcomes
probability
getting
outcome
``
head-head
''
1
4
outcomes
numerical
terms
1/4
0.25
25
however
comes
practical
application
two
major
competing
categories
probability
interpretations
whose
adherents
possess
different
views
fundamental
nature
probability
objectivists
assign
numbers
describe
objective
physical
state
affairs
popular
version
objective
probability
frequentist
probability
claims
probability
random
event
denotes
relative
frequency
occurrence
experiment
's
outcome
repeating
experiment
interpretation
considers
probability
relative
frequency
``
long
run
''
outcomes
modification
propensity
probability
interprets
probability
tendency
experiment
yield
certain
outcome
even
performed
subjectivists
assign
numbers
per
subjective
probability
i.e.
degree
belief
degree
belief
interpreted
``
price
would
buy
sell
bet
pays
1
unit
utility
e
0
e.
''
popular
version
subjective
probability
bayesian
probability
includes
expert
knowledge
well
experimental
data
produce
probabilities
expert
knowledge
represented
subjective
prior
probability
distribution
data
incorporated
likelihood
function
product
prior
likelihood
normalized
results
posterior
probability
distribution
incorporates
information
known
date
aumann
's
agreement
theorem
bayesian
agents
whose
prior
beliefs
similar
end
similar
posterior
beliefs
however
sufficiently
different
priors
lead
different
conclusions
regardless
much
information
agents
share
==
etymology
==
word
probability
derives
latin
probabilitas
also
mean
``
probity
''
measure
authority
witness
legal
case
europe
often
correlated
witness
's
nobility
sense
differs
much
modern
meaning
probability
contrast
measure
weight
empirical
evidence
arrived
inductive
reasoning
statistical
inference
==
history
==
scientific
study
probability
modern
development
mathematics
gambling
shows
interest
quantifying
ideas
probability
millennia
exact
mathematical
descriptions
arose
much
later
reasons
slow
development
mathematics
probability
whereas
games
chance
provided
impetus
mathematical
study
probability
fundamental
issues
still
obscured
superstitions
gamblers
according
richard
jeffrey
``
middle
seventeenth
century
term
'probable
latin
probabilis
meant
approvable
applied
sense
univocally
opinion
action
probable
action
opinion
one
sensible
people
would
undertake
hold
circumstances
''
however
legal
contexts
especially
'probable
could
also
apply
propositions
good
evidence
earliest
known
forms
probability
statistics
developed
middle
eastern
mathematicians
studying
cryptography
8th
13th
centuries
al-khalil
717–786
wrote
book
cryptographic
messages
contains
first
use
permutations
combinations
list
possible
arabic
words
without
vowels
al-kindi
801–873
made
earliest
known
use
statistical
inference
work
cryptanalysis
frequency
analysis
important
contribution
ibn
adlan
1187–1268
sample
size
use
frequency
analysis
sixteenth
century
italian
polymath
gerolamo
cardano
demonstrated
efficacy
defining
odds
ratio
favourable
unfavourable
outcomes
implies
probability
event
given
ratio
favourable
outcomes
total
number
possible
outcomes
aside
elementary
work
cardano
doctrine
probabilities
dates
correspondence
pierre
de
fermat
blaise
pascal
1654
christiaan
huygens
1657
gave
earliest
known
scientific
treatment
subject
jakob
bernoulli
's
ars
conjectandi
posthumous
1713
abraham
de
moivre
's
doctrine
chances
1718
treated
subject
branch
mathematics
see
ian
hacking
's
emergence
probability
james
franklin
's
science
conjecture
histories
early
development
concept
mathematical
probability
theory
errors
may
traced
back
roger
cotes
's
opera
miscellanea
posthumous
1722
memoir
prepared
thomas
simpson
1755
printed
1756
first
applied
theory
discussion
errors
observation
reprint
1757
memoir
lays
axioms
positive
negative
errors
equally
probable
certain
assignable
limits
define
range
errors
simpson
also
discusses
continuous
errors
describes
probability
curve
first
two
laws
error
proposed
originated
pierre-simon
laplace
first
law
published
1774
stated
frequency
error
could
expressed
exponential
function
numerical
magnitude
error
disregarding
sign
second
law
error
proposed
1778
laplace
stated
frequency
error
exponential
function
square
error
second
law
error
called
normal
distribution
gauss
law
``
difficult
historically
attribute
law
gauss
spite
well-known
precocity
probably
made
discovery
two
years
old
``
daniel
bernoulli
1778
introduced
principle
maximum
product
probabilities
system
concurrent
errors
adrien-marie
legendre
1805
developed
method
least
squares
introduced
nouvelles
méthodes
pour
la
détermination
des
orbites
des
comètes
new
methods
determining
orbits
comets
ignorance
legendre
's
contribution
irish-american
writer
robert
adrain
editor
``
analyst
''
1808
first
deduced
law
facility
error
ϕ
x
c
e
−
h
2
x
2
\displaystyle
\phi
x
=ce^
-h^
2
x^
2
h
\displaystyle
h
constant
depending
precision
observation
c
\displaystyle
c
scale
factor
ensuring
area
curve
equals
1.
gave
two
proofs
second
essentially
john
herschel
's
1850
gauss
gave
first
proof
seems
known
europe
third
adrain
's
1809.
proofs
given
laplace
1810
1812
gauss
1823
james
ivory
1825
1826
hagen
1837
friedrich
bessel
1838
w.f
donkin
1844
1856
morgan
crofton
1870
contributors
ellis
1844
de
morgan
1864
glaisher
1872
giovanni
schiaparelli
1875
peters
's
1856
formula
r
probable
error
single
observation
well
known
nineteenth
century
authors
general
theory
included
laplace
sylvestre
lacroix
1816
littrow
1833
adolphe
quetelet
1853
richard
dedekind
1860
helmert
1872
hermann
laurent
1873
liagre
didion
karl
pearson
augustus
de
morgan
george
boole
improved
exposition
theory
andrey
markov
introduced
notion
markov
chains
1906
played
important
role
stochastic
processes
theory
applications
modern
theory
probability
based
measure
theory
developed
andrey
kolmogorov
1931
.on
geometric
side
see
integral
geometry
contributors
educational
times
influential
miller
crofton
mccoll
wolstenholme
watson
artemas
martin
==
theory
==
like
theories
theory
probability
representation
concepts
formal
terms—that
terms
considered
separately
meaning
formal
terms
manipulated
rules
mathematics
logic
results
interpreted
translated
back
problem
domain
least
two
successful
attempts
formalize
probability
namely
kolmogorov
formulation
cox
formulation
kolmogorov
's
formulation
see
probability
space
sets
interpreted
events
probability
measure
class
sets
cox
's
theorem
probability
taken
primitive
analyzed
emphasis
constructing
consistent
assignment
probability
values
propositions
cases
laws
probability
except
technical
details
methods
quantifying
uncertainty
dempster–shafer
theory
possibility
theory
essentially
different
compatible
laws
probability
usually
understood
==
applications
==
probability
theory
applied
everyday
life
risk
assessment
modeling
insurance
industry
markets
use
actuarial
science
determine
pricing
make
trading
decisions
governments
apply
probabilistic
methods
environmental
regulation
entitlement
analysis
reliability
theory
aging
longevity
financial
regulation
good
example
use
probability
theory
equity
trading
effect
perceived
probability
widespread
middle
east
conflict
oil
prices
ripple
effects
economy
whole
assessment
commodity
trader
war
likely
send
commodity
's
prices
signals
traders
opinion
accordingly
probabilities
neither
assessed
independently
necessarily
rationally
theory
behavioral
finance
emerged
describe
effect
groupthink
pricing
policy
peace
conflict
addition
financial
assessment
probability
used
analyze
trends
biology
e.g
disease
spread
well
ecology
e.g
biological
punnett
squares
finance
risk
assessment
used
statistical
tool
calculate
likelihood
undesirable
events
occurring
assist
implementing
protocols
avoid
encountering
circumstances
probability
used
design
games
chance
casinos
make
guaranteed
profit
yet
provide
payouts
players
frequent
enough
encourage
continued
play
discovery
rigorous
methods
assess
combine
probability
assessments
changed
society
another
significant
application
probability
theory
everyday
life
reliability
many
consumer
products
automobiles
consumer
electronics
use
reliability
theory
product
design
reduce
probability
failure
failure
probability
may
influence
manufacturer
's
decisions
product
's
warranty
cache
language
model
statistical
language
models
used
natural
language
processing
also
examples
applications
probability
theory
==
mathematical
treatment
==
consider
experiment
produce
number
results
collection
possible
results
called
sample
space
experiment
power
set
sample
space
formed
considering
different
collections
possible
results
example
rolling
die
produce
six
possible
results
one
collection
possible
results
gives
odd
number
die
thus
subset
1,3,5
element
power
set
sample
space
dice
rolls
collections
called
``
events
''
case
1,3,5
event
die
falls
odd
number
results
actually
occur
fall
given
event
event
said
occurred
probability
way
assigning
every
event
value
zero
one
requirement
event
made
possible
results
example
event
1,2,3,4,5,6
assigned
value
one
qualify
probability
assignment
values
must
satisfy
requirement
look
collection
mutually
exclusive
events
events
common
results
e.g.
events
1,6
3
2,4
mutually
exclusive
probability
least
one
events
occur
given
sum
probabilities
individual
events
probability
event
written
p
\displaystyle
p
p
\displaystyle
p
pr
\displaystyle
\text
pr
mathematical
definition
probability
extend
infinite
sample
spaces
even
uncountable
sample
spaces
using
concept
measure
opposite
complement
event
event
event
occurring
often
denoted
¯
∁
¬
\displaystyle
\overline
a^
\complement
\neg
∼
\displaystyle
\sim
probability
given
p
1
−
p
example
chance
rolling
six
six-sided
die
1
–
chance
rolling
six
1
−
1
6
5
6
\displaystyle
=1-
\tfrac
1
6
\tfrac
5
6
see
complementary
event
complete
treatment
two
events
b
occur
single
performance
experiment
called
intersection
joint
probability
b
denoted
p
∩
b
\displaystyle
p
a\cap
b
===
independent
events
===
two
events
b
independent
joint
probability
p
b
p
∩
b
p
p
b
\displaystyle
p
\mbox
b
=p
a\cap
b
=p
p
b
example
two
coins
flipped
chance
heads
1
2
×
1
2
1
4
\displaystyle
\tfrac
1
2
\times
\tfrac
1
2
\tfrac
1
4
===
mutually
exclusive
events
===
either
event
event
b
never
occurs
single
performance
experiment
called
mutually
exclusive
events
two
events
mutually
exclusive
probability
occurring
denoted
p
∩
b
\displaystyle
p
a\cap
b
p
b
p
∩
b
0
\displaystyle
p
\mbox
b
=p
a\cap
b
=0
two
events
mutually
exclusive
probability
either
occurring
denoted
p
∪
b
\displaystyle
p
a\cup
b
p
b
p
∪
b
p
p
b
−
p
∩
b
p
p
b
−
0
p
p
b
\displaystyle
p
\mbox
b
=p
a\cup
b
=p
+p
b
-p
a\cap
b
=p
+p
b
-0=p
+p
b
example
chance
rolling
1
2
six-sided
die
p
1
2
p
1
p
2
1
6
1
6
1
3
\displaystyle
p
1
\mbox
2
=p
1
+p
2
\tfrac
1
6
\tfrac
1
6
\tfrac
1
3
===
mutually
exclusive
events
===
events
mutually
exclusive
p
b
p
∪
b
p
p
b
−
p
b
\displaystyle
p\left
\hbox
b\right
=p
a\cup
b
=p\left
a\right
+p\left
b\right
-p\left
\mbox
b\right
example
drawing
single
card
random
regular
deck
cards
chance
getting
heart
face
card
j
q
k
one
13
52
12
52
−
3
52
11
26
\displaystyle
\tfrac
13
52
\tfrac
12
52
\tfrac
3
52
\tfrac
11
26
52
cards
deck
13
hearts
12
face
cards
3
possibilities
included
``
3
''
included
``
13
hearts
''
``
12
face
cards
''
counted
===
conditional
probability
===
conditional
probability
probability
event
given
occurrence
event
b.
conditional
probability
written
p
∣
b
\displaystyle
p
a\mid
b
read
``
probability
given
b
''
defined
p
∣
b
p
∩
b
p
b
\displaystyle
p
a\mid
b
\frac
p
a\cap
b
p
b
.\
p
b
0
\displaystyle
p
b
=0
p
∣
b
\displaystyle
p
a\mid
b
formally
undefined
expression
however
possible
define
conditional
probability
zero-probability
events
using
σ-algebra
events
arising
continuous
random
variable
.for
example
bag
2
red
balls
2
blue
balls
4
balls
total
probability
taking
red
ball
1
2
\displaystyle
1/2
however
taking
second
ball
probability
either
red
ball
blue
ball
depends
ball
previously
taken
red
ball
taken
probability
picking
red
ball
would
1
3
\displaystyle
1/3
since
1
red
2
blue
balls
would
remaining
===
inverse
probability
===
probability
theory
applications
bayes
rule
relates
odds
event
1
\displaystyle
a_
1
event
2
\displaystyle
a_
2
prior
posterior
conditioning
another
event
b
\displaystyle
b
odds
1
\displaystyle
a_
1
event
2
\displaystyle
a_
2
simply
ratio
probabilities
two
events
arbitrarily
many
events
\displaystyle
interest
two
rule
rephrased
posterior
proportional
prior
times
likelihood
p
b
∝
p
p
b
\displaystyle
p
a|b
\propto
p
p
b|a
proportionality
symbol
means
left
hand
side
proportional
i.e.
equals
constant
times
right
hand
side
\displaystyle
varies
fixed
given
b
\displaystyle
b
lee
2012
bertsch
mcgrayne
2012
form
goes
back
laplace
1774
cournot
1843
see
fienberg
2005
see
inverse
probability
bayes
rule
===
summary
probabilities
===
==
relation
randomness
probability
quantum
mechanics
==
deterministic
universe
based
newtonian
concepts
would
probability
conditions
known
laplace
's
demon
situations
sensitivity
initial
conditions
exceeds
ability
measure
i.e
know
case
roulette
wheel
force
hand
period
force
known
number
ball
stop
would
certainty
though
practical
matter
would
likely
true
roulette
wheel
exactly
levelled
–
thomas
a.
bass
newtonian
casino
revealed
also
assumes
knowledge
inertia
friction
wheel
weight
smoothness
roundness
ball
variations
hand
speed
turning
forth
probabilistic
description
thus
useful
newtonian
mechanics
analyzing
pattern
outcomes
repeated
rolls
roulette
wheel
physicists
face
situation
kinetic
theory
gases
system
deterministic
principle
complex
number
molecules
typically
order
magnitude
avogadro
constant
6.02×1023
statistical
description
properties
feasible
probability
theory
required
describe
quantum
phenomena
revolutionary
discovery
early
20th
century
physics
random
character
physical
processes
occur
sub-atomic
scales
governed
laws
quantum
mechanics
objective
wave
function
evolves
deterministically
according
copenhagen
interpretation
deals
probabilities
observing
outcome
explained
wave
function
collapse
observation
made
however
loss
determinism
sake
instrumentalism
meet
universal
approval
albert
einstein
famously
remarked
letter
max
born
``
convinced
god
play
dice
''
like
einstein
erwin
schrödinger
discovered
wave
function
believed
quantum
mechanics
statistical
approximation
underlying
deterministic
reality
modern
interpretations
statistical
mechanics
measurement
quantum
decoherence
invoked
account
appearance
subjectively
probabilistic
experimental
outcomes
==
see
also
==
chance
disambiguation
class
membership
probabilities
contingency
equiprobability
heuristics
judgment
decision-making
probability
theory
randomness
statistics
estimators
estimation
theory
probability
density
functionin
lawbalance
probabilities
==
notes
==
==
references
==
==
bibliography
==
kallenberg
2005
probabilistic
symmetries
invariance
principles
springer-verlag
new
york
510
pp
isbn
0-387-25115-4
kallenberg
2002
foundations
modern
probability
2nd
ed
springer
series
statistics
650
pp
isbn
0-387-95313-2
olofsson
peter
2005
probability
statistics
stochastic
processes
wiley-interscience
504
pp
isbn
0-471-67969-0
==
external
links
==
virtual
laboratories
probability
statistics
univ
ala.-huntsville
probability
time
bbc
probability
statistics
ebook
edwin
thompson
jaynes
probability
theory
logic
science
preprint
washington
university
1996
—
html
index
links
postscript
files
pdf
first
three
chapters
people
history
probability
statistics
univ
southampton
probability
statistics
earliest
uses
pages
univ
southampton
earliest
uses
symbols
probability
statistics
earliest
uses
various
mathematical
symbols
tutorial
probability
bayes
theorem
devised
first-year
oxford
university
students
1
pdf
file
anthology
chance
operations
1963
ubuweb
introduction
probability
–
ebook
charles
grinstead
laurie
snell
source
gnu
free
documentation
license
english
italian
bruno
de
finetti
probabilità
e
induzione
bologna
clueb
1993.
isbn
88-8091-176-7
digital
version
richard
p.
feynman
's
lecture
probability
https
//en.wikipedia.org/wiki/python_
programming_language
evel
general-purpose
programming
language
created
guido
van
rossum
first
released
1991
python
's
design
philosophy
emphasizes
code
readability
notable
use
significant
whitespace
language
constructs
object-oriented
approach
aim
help
programmers
write
clear
logical
code
small
large-scale
projects
python
dynamically
typed
garbage-collected
supports
multiple
programming
paradigms
including
structured
particularly
procedural
object-oriented
functional
programming
python
often
described
``
batteries
included
''
language
due
comprehensive
standard
library
python
conceived
late
1980s
successor
abc
language
python
2.0
released
2000
introduced
features
like
list
comprehensions
garbage
collection
system
capable
collecting
reference
cycles
python
3.0
released
2008
major
revision
language
completely
backward-compatible
much
python
2
code
run
unmodified
python
3.
python
2
language
i.e
python
2.7.x
officially
discontinued
1
january
2020
first
planned
2015
security
patches
improvements
released
python
2
's
end-of-life
python
3.5.x
later
supported
python
interpreters
available
many
operating
systems
global
community
programmers
develops
maintains
cpython
open
source
reference
implementation
non-profit
organization
python
software
foundation
manages
directs
resources
python
cpython
development
==
history
==
python
conceived
late
1980s
guido
van
rossum
centrum
wiskunde
informatica
cwi
netherlands
successor
abc
language
inspired
setl
capable
exception
handling
interfacing
amoeba
operating
system
implementation
began
december
1989.
van
rossum
shouldered
sole
responsibility
project
lead
developer
12
july
2018
announced
``
permanent
vacation
''
responsibilities
python
's
benevolent
dictator
life
title
python
community
bestowed
upon
reflect
long-term
commitment
project
's
chief
decision-maker
shares
leadership
member
five-person
steering
council
january
2019
active
python
core
developers
elected
brett
cannon
nick
coghlan
barry
warsaw
carol
willing
van
rossum
five-member
``
steering
council
''
lead
project
python
2.0
released
16
october
2000
many
major
new
features
including
cycle-detecting
garbage
collector
support
unicode
python
3.0
released
3
december
2008.
major
revision
language
completely
backward-compatible
many
major
features
backported
python
2.6.x
2.7.x
version
series
releases
python
3
include
2to3
utility
automates
least
partially
translation
python
2
code
python
3.python
2.7
's
end-of-life
date
initially
set
2015
postponed
2020
concern
large
body
existing
code
could
easily
forward-ported
python
3
==
features
philosophy
==
python
multi-paradigm
programming
language
object-oriented
programming
structured
programming
fully
supported
many
features
support
functional
programming
aspect-oriented
programming
including
metaprogramming
metaobjects
magic
methods
many
paradigms
supported
via
extensions
including
design
contract
logic
programming
python
uses
dynamic
typing
combination
reference
counting
cycle-detecting
garbage
collector
memory
management
also
features
dynamic
name
resolution
late
binding
binds
method
variable
names
program
execution
python
's
design
offers
support
functional
programming
lisp
tradition
filter
map
reduce
functions
list
comprehensions
dictionaries
sets
generator
expressions
standard
library
two
modules
itertools
functools
implement
functional
tools
borrowed
haskell
standard
ml
language
's
core
philosophy
summarized
document
zen
python
pep
20
includes
aphorisms
beautiful
better
ugly
explicit
better
implicit
simple
better
complex
complex
better
complicated
readability
counts
rather
functionality
built
core
python
designed
highly
extensible
compact
modularity
made
particularly
popular
means
adding
programmable
interfaces
existing
applications
van
rossum
's
vision
small
core
language
large
standard
library
easily
extensible
interpreter
stemmed
frustrations
abc
espoused
opposite
approach
python
strives
simpler
less-cluttered
syntax
grammar
giving
developers
choice
coding
methodology
contrast
perl
's
``
one
way
''
motto
python
embraces
``
one—and
preferably
one—obvious
way
''
design
philosophy
alex
martelli
fellow
python
software
foundation
python
book
author
writes
``
describe
something
'clever
considered
compliment
python
culture
``
python
's
developers
strive
avoid
premature
optimization
reject
patches
non-critical
parts
cpython
reference
implementation
would
offer
marginal
increases
speed
cost
clarity
speed
important
python
programmer
move
time-critical
functions
extension
modules
written
languages
c
use
pypy
just-in-time
compiler
cython
also
available
translates
python
script
c
makes
direct
c-level
api
calls
python
interpreter
important
goal
python
's
developers
keeping
fun
use
reflected
language
's
name—a
tribute
british
comedy
group
monty
python—and
occasionally
playful
approaches
tutorials
reference
materials
examples
refer
spam
eggs
famous
monty
python
sketch
instead
standard
foo
bar
common
neologism
python
community
pythonic
wide
range
meanings
related
program
style
say
code
pythonic
say
uses
python
idioms
well
natural
shows
fluency
language
conforms
python
's
minimalist
philosophy
emphasis
readability
contrast
code
difficult
understand
reads
like
rough
transcription
another
programming
language
called
unpythonic
users
admirers
python
especially
considered
knowledgeable
experienced
often
referred
pythonistas
==
syntax
semantics
==
python
meant
easily
readable
language
formatting
visually
uncluttered
often
uses
english
keywords
languages
use
punctuation
unlike
many
languages
use
curly
brackets
delimit
blocks
semicolons
statements
optional
fewer
syntactic
exceptions
special
cases
c
pascal
===
indentation
===
python
uses
whitespace
indentation
rather
curly
brackets
keywords
delimit
blocks
increase
indentation
comes
certain
statements
decrease
indentation
signifies
end
current
block
thus
program
's
visual
structure
accurately
represents
program
's
semantic
structure
feature
sometimes
termed
off-side
rule
languages
share
languages
indentation
n't
semantic
meaning
===
statements
control
flow
===
python
's
statements
include
among
others
assignment
statement
token
'=
equals
sign
operates
differently
traditional
imperative
programming
languages
fundamental
mechanism
including
nature
python
's
version
variables
illuminates
many
features
language
assignment
c
e.g.
x
2
translates
``
typed
variable
name
x
receives
copy
numeric
value
2
''
right-hand
value
copied
allocated
storage
location
left-hand
variable
name
symbolic
address
memory
allocated
variable
large
enough
potentially
quite
large
declared
type
simplest
case
python
assignment
using
example
x
2
translates
``
generic
name
x
receives
reference
separate
dynamically
allocated
object
numeric
int
type
value
2
''
termed
binding
name
object
since
name
's
storage
location
n't
contain
indicated
value
improper
call
variable
names
may
subsequently
rebound
time
objects
greatly
varying
types
including
strings
procedures
complex
objects
data
methods
etc
successive
assignments
common
value
multiple
names
e.g.
x
2
2
z
2
result
allocating
storage
three
names
one
numeric
object
three
names
bound
since
name
generic
reference
holder
unreasonable
associate
fixed
data
type
however
given
time
name
bound
object
type
thus
dynamic
typing
statement
conditionally
executes
block
code
along
else
elif
contraction
else-if
statement
iterates
iterable
object
capturing
element
local
variable
use
attached
block
statement
executes
block
code
long
condition
true
try
statement
allows
exceptions
raised
attached
code
block
caught
handled
except
clauses
also
ensures
clean-up
code
finally
block
always
run
regardless
block
exits
raise
statement
used
raise
specified
exception
re-raise
caught
exception
class
statement
executes
block
code
attaches
local
namespace
class
use
object-oriented
programming
def
statement
defines
function
method
statement
python
2.5
released
september
2006
encloses
code
block
within
context
manager
example
acquiring
lock
block
code
run
releasing
lock
afterwards
opening
file
closing
allowing
resource
acquisition
initialization
raii
-like
behavior
replaces
common
try/finally
idiom
break
statement
exits
loop
continue
statement
skips
iteration
continues
next
item
pass
statement
serves
nop
syntactically
needed
create
empty
code
block
assert
statement
used
debugging
check
conditions
ought
apply
yield
statement
returns
value
generator
function
python
2.5
yield
also
operator
form
used
implement
coroutines
import
statement
used
import
modules
whose
functions
variables
used
current
program
three
ways
using
import
import
module
name
alias
module
name
import
module
name
import
definition
1
alias
1
definition
2
alias
2
....
print
statement
changed
print
function
python
3.python
support
tail
call
optimization
first-class
continuations
according
guido
van
rossum
never
however
better
support
coroutine-like
functionality
provided
2.5
extending
python
's
generators
2.5
generators
lazy
iterators
information
passed
unidirectionally
generator
python
2.5
possible
pass
information
back
generator
function
python
3.3
information
passed
multiple
stack
levels
===
expressions
===
python
expressions
similar
languages
c
java
addition
subtraction
multiplication
behavior
division
differs
two
types
divisions
python
floor
division
integer
division
//
floating
point/division
python
also
added
operator
exponentiation
python
3.5
new
infix
operator
introduced
intended
used
libraries
numpy
matrix
multiplication
python
3.8
syntax
called
'walrus
operator
introduced
assigns
values
variables
part
larger
expression
python
==
compares
value
versus
java
compares
numerics
value
objects
reference
value
comparisons
java
objects
performed
equals
method
python
's
operator
may
used
compare
object
identities
comparison
reference
python
comparisons
may
chained
example
b
c.
python
uses
words
boolean
operators
rather
symbolic
||
used
java
c.
python
type
expression
termed
list
comprehension
python
2.4
extended
list
comprehensions
general
expression
termed
generator
expression
anonymous
functions
implemented
using
lambda
expressions
however
limited
body
one
expression
conditional
expressions
python
written
x
c
else
different
order
operands
c
x
operator
common
many
languages
python
makes
distinction
lists
tuples
lists
written
1
2
3
mutable
used
keys
dictionaries
dictionary
keys
must
immutable
python
tuples
written
1
2
3
immutable
thus
used
keys
dictionaries
provided
elements
tuple
immutable
operator
used
concatenate
two
tuples
directly
modify
contents
rather
produces
new
tuple
containing
elements
provided
tuples
thus
given
variable
initially
equal
1
2
3
executing
4
5
first
evaluates
4
5
yields
1
2
3
4
5
assigned
back
thereby
effectively
``
modifying
contents
''
conforming
immutable
nature
tuple
objects
parentheses
optional
tuples
unambiguous
contexts
python
features
sequence
unpacking
wherein
multiple
expressions
evaluating
anything
assigned
variable
writable
property
etc
associated
identical
manner
forming
tuple
literals
whole
put
left
hand
side
equal
sign
assignment
statement
statement
expects
iterable
object
right
hand
side
equal
sign
produces
number
values
provided
writable
expressions
iterated
iterate
assigning
produced
values
corresponding
expression
left
python
``
string
format
''
operator
functions
analogous
printf
format
strings
c
e.g
``
spam=
eggs=
''
``
blah
''
2
evaluates
``
spam=blah
eggs=2
''
python
3
2.6+
supplemented
format
method
str
class
e.g
``
spam=
0
eggs=
1
''
.format
``
blah
''
2
python
3.6
added
``
f-strings
''
blah
``
blah
''
eggs
2
f'spam=
blah
eggs=
eggs
python
various
kinds
string
literals
strings
delimited
single
double
quote
marks
unlike
unix
shells
perl
perl-influenced
languages
single
quote
marks
double
quote
marks
function
identically
kinds
string
use
backslash
escape
character
string
interpolation
became
available
python
3.6
``
formatted
string
literals
''
triple-quoted
strings
begin
end
series
three
single
double
quote
marks
may
span
multiple
lines
function
like
documents
shells
perl
ruby
raw
string
varieties
denoted
prefixing
string
literal
r.
escape
sequences
interpreted
hence
raw
strings
useful
literal
backslashes
common
regular
expressions
windows-style
paths
compare
``
-quoting
''
c
python
array
index
array
slicing
expressions
lists
denoted
key
start
stop
start
stop
step
indexes
zero-based
negative
indexes
relative
end
slices
take
elements
start
index
including
stop
index
third
slice
parameter
called
step
stride
allows
elements
skipped
reversed
slice
indexes
may
omitted
example
returns
copy
entire
list
element
slice
shallow
copy
python
distinction
expressions
statements
rigidly
enforced
contrast
languages
common
lisp
scheme
ruby
leads
duplicating
functionality
example
list
comprehensions
vs.
for-loops
conditional
expressions
vs.
blocks
eval
vs.
exec
built-in
functions
python
2
exec
statement
former
expressions
latter
statements
statements
part
expression
list
comprehensions
lambda
expressions
expressions
contain
statements
particular
case
assignment
statement
1
form
part
conditional
expression
conditional
statement
advantage
avoiding
classic
c
error
mistaking
assignment
operator
equality
operator
==
conditions
c
1
...
syntactically
valid
probably
unintended
c
code
c
1
...
causes
syntax
error
python
===
methods
===
methods
objects
functions
attached
object
's
class
syntax
instance.method
argument
normal
methods
functions
syntactic
sugar
class.method
instance
argument
python
methods
explicit
self
parameter
access
instance
data
contrast
implicit
self
object-oriented
programming
languages
e.g.
c++
java
objective-c
ruby
===
typing
===
python
uses
duck
typing
typed
objects
untyped
variable
names
type
constraints
checked
compile
time
rather
operations
object
may
fail
signifying
given
object
suitable
type
despite
dynamically
typed
python
strongly
typed
forbidding
operations
well-defined
example
adding
number
string
rather
silently
attempting
make
sense
python
allows
programmers
define
types
using
classes
often
used
object-oriented
programming
new
instances
classes
constructed
calling
class
example
spamclass
eggsclass
classes
instances
metaclass
type
instance
allowing
metaprogramming
reflection
version
3.0
python
two
kinds
classes
old-style
new-style
syntax
styles
difference
whether
class
object
inherited
directly
indirectly
new-style
classes
inherit
object
instances
type
versions
python
2
python
2.2
onwards
kinds
classes
used
old-style
classes
eliminated
python
3.0.
long
term
plan
support
gradual
typing
python
3.5
syntax
language
allows
specifying
static
types
checked
default
implementation
cpython
experimental
optional
static
type
checker
named
mypy
supports
compile-time
type
checking
^a
directly
accessible
name
===
mathematics
===
python
usual
symbols
arithmetic
operators
floor
division
operator
//
remainder
operator
remainder
negative
e.g
4
-3
==
-2
also
exponentiation
e.g
5
3
==
125
9
0.5
==
3.0
matrix
multiply
operator
operators
work
like
traditional
math
precedence
rules
operators
infix
also
unary
represent
positive
negative
numbers
respectively
division
integers
produces
floating
point
results
behavior
division
changed
significantly
time
python
2.1
earlier
used
c
's
division
behavior
operator
integer
division
operands
integers
floating-point
division
otherwise
integer
division
rounds
towards
0
e.g
7/3
==
2
-7/3
==
-2.
python
2.2
changed
integer
division
round
towards
negative
infinity
e.g
7/3
==
2
-7/3
==
-3.
floor
division
//
operator
introduced
7//3
==
2
-7//3
==
-3
7.5//3
==
2.0
-7.5//3
==
-3.0.
adding
__future__
import
division
causes
module
use
python
3.0
rules
division
see
next
python
3.0
changed
always
floating-point
division
e.g
5/2
==
2.5.in
python
terms
true
division
simply
division
//
floor
division
version
3.0
classic
division
rounding
towards
negative
infinity
though
different
languages
adds
consistency
instance
means
equation
b
//b
==
a//b
1
always
true
also
means
equation
b
a//b
b
==
valid
positive
negative
values
a.
however
maintaining
validity
equation
means
result
b
expected
half-open
interval
0
b
b
positive
integer
lie
interval
b
0
b
negative
python
provides
round
function
rounding
float
nearest
integer
tie-breaking
python
3
uses
round
even
round
1.5
round
2.5
produce
2.
versions
3
used
round-away-from-zero
round
0.5
1.0
round
-0.5
−1.0.python
allows
boolean
expressions
multiple
equality
relations
manner
consistent
general
use
mathematics
example
expression
b
c
tests
whether
less
b
b
less
c.
c-derived
languages
interpret
expression
differently
c
expression
would
first
evaluate
b
resulting
0
1
result
would
compared
c.
python
uses
arbitrary-precision
arithmetic
integer
operations
decimal
type/class
decimal
module
provides
decimal
floating
point
numbers
pre-defined
arbitrary
precision
several
rounding
modes
fraction
class
fractions
module
provides
arbitrary
precision
rational
numbers
due
python
's
extensive
mathematics
library
third-party
library
numpy
extends
native
capabilities
frequently
used
scientific
scripting
language
aid
problems
numerical
data
processing
manipulation
==
python
programming
examples
==
hello
world
program
program
calculate
factorial
positive
integer
==
libraries
==
python
's
large
standard
library
commonly
cited
one
greatest
strengths
provides
tools
suited
many
tasks
internet-facing
applications
many
standard
formats
protocols
mime
http
supported
includes
modules
creating
graphical
user
interfaces
connecting
relational
databases
generating
pseudorandom
numbers
arithmetic
arbitrary-precision
decimals
manipulating
regular
expressions
unit
testing
parts
standard
library
covered
specifications
example
web
server
gateway
interface
wsgi
implementation
wsgiref
follows
pep
333
modules
specified
code
internal
documentation
test
suites
however
standard
library
cross-platform
python
code
modules
need
altering
rewriting
variant
implementations
november
2019
python
package
index
pypi
official
repository
third-party
python
software
contains
200,000
packages
wide
range
functionality
including
graphical
user
interfaces
web
frameworks
multimedia
databases
networking
test
frameworks
automation
web
scraping
documentation
system
administration
scientific
computing
text
processing
image
processing
machine
learning
data
analytics
==
development
environments
==
python
implementations
including
cpython
include
read–eval–print
loop
repl
permitting
function
command
line
interpreter
user
enters
statements
sequentially
receives
results
immediately
shells
including
idle
ipython
add
abilities
improved
auto-completion
session
state
retention
syntax
highlighting
well
standard
desktop
integrated
development
environments
web
browser-based
ides
sagemath
intended
developing
science
math-related
python
programs
pythonanywhere
browser-based
ide
hosting
environment
canopy
ide
commercial
python
ide
emphasizing
scientific
computing
==
implementations
==
===
reference
implementation
===
cpython
reference
implementation
python
written
c
meeting
c89
standard
several
select
c99
features
compiles
python
programs
intermediate
bytecode
executed
virtual
machine
cpython
distributed
large
standard
library
written
mixture
c
native
python
available
many
platforms
including
windows
modern
unix-like
systems
platform
portability
one
earliest
priorities
===
implementations
===
pypy
fast
compliant
interpreter
python
2.7
3.6.
just-in-time
compiler
brings
significant
speed
improvement
cpython
several
libraries
written
c
used
stackless
python
significant
fork
cpython
implements
microthreads
use
c
memory
stack
thus
allowing
massively
concurrent
programs
pypy
also
stackless
version
micropython
circuitpython
python
3
variants
optimized
microcontrollers
includes
lego
mindstorms
ev3
===
unsupported
implementations
===
just-in-time
python
compilers
developed
unsupported
google
began
project
named
unladen
swallow
2009
aim
speeding
python
interpreter
five-fold
using
llvm
improving
multithreading
ability
scale
thousands
cores
ordinary
implementations
suffer
global
interpreter
lock
psyco
just-in-time
specializing
compiler
integrates
cpython
transforms
bytecode
machine
code
runtime
emitted
code
specialized
certain
data
types
faster
standard
python
code
2005
nokia
released
python
interpreter
series
60
mobile
phones
named
pys60
includes
many
modules
cpython
implementations
additional
modules
integrate
symbian
operating
system
project
kept
up-to-date
run
variants
s60
platform
several
third-party
modules
available
nokia
n900
also
supports
python
gtk
widget
libraries
enabling
programs
written
run
target
device
cross-compilers
languages
===
several
compilers
high-level
object
languages
either
unrestricted
python
restricted
subset
python
language
similar
python
source
language
jython
enables
use
java
class
library
python
program
ironpython
follows
similar
approach
order
run
python
programs
.net
common
language
runtime
rpython
language
compiled
c
used
build
pypy
interpreter
python
pyjs
compiles
python
javascript
cython
compiles
python
c
c++
numba
uses
llvm
compile
python
machine
code
pythran
compiles
python
c++
somewhat
dated
pyrex
latest
release
2010
shed
skin
latest
release
2013
compile
c
c++
respectively
google
's
grumpy
compiles
python
go
myhdl
compiles
python
vhdl
nuitka
compiles
python
c++
===
performance
===
performance
comparison
various
python
implementations
non-numerical
combinatorial
workload
presented
euroscipy
'13
==
development
==
python
's
development
conducted
largely
python
enhancement
proposal
pep
process
primary
mechanism
proposing
major
new
features
collecting
community
input
issues
documenting
python
design
decisions
python
coding
style
covered
pep
8.
outstanding
peps
reviewed
commented
python
community
steering
council
enhancement
language
corresponds
development
cpython
reference
implementation
mailing
list
python-dev
primary
forum
language
's
development
specific
issues
discussed
roundup
bug
tracker
hosted
bugs.python.org
development
originally
took
place
self-hosted
source-code
repository
running
mercurial
python
moved
github
january
2017.cpython
's
public
releases
come
three
types
distinguished
part
version
number
incremented
backward-incompatible
versions
code
expected
break
need
manually
ported
first
part
version
number
incremented
releases
happen
infrequently—for
example
version
3.0
released
8
years
2.0.
major
``
feature
''
releases
every
18
months
largely
compatible
introduce
new
features
second
part
version
number
incremented
major
version
supported
bugfixes
several
years
release
bugfix
releases
introduce
new
features
occur
every
3
months
made
sufficient
number
bugs
fixed
upstream
since
last
release
security
vulnerabilities
also
patched
releases
third
final
part
version
number
incremented
python
3.9
alpha1
announced
november
2019
adoption
new
yearly
release
cadence
first
release
3.9
slated
november
2020.many
alpha
beta
release-candidates
also
released
previews
testing
final
releases
although
rough
schedule
release
often
delayed
code
ready
python
's
development
team
monitors
state
code
running
large
unit
test
suite
development
using
buildbot
continuous
integration
system
major
academic
conference
python
pycon
also
special
python
mentoring
programmes
pyladies
==
naming
==
python
's
name
derived
british
comedy
group
monty
python
python
creator
guido
van
rossum
enjoyed
developing
language
monty
python
references
appear
frequently
python
code
culture
example
metasyntactic
variables
often
used
python
literature
spam
eggs
instead
traditional
foo
bar
official
python
documentation
also
contains
various
references
monty
python
routines
prefix
py-
used
show
something
related
python
examples
use
prefix
names
python
applications
libraries
include
pygame
binding
sdl
python
commonly
used
create
games
pyqt
pygtk
bind
qt
gtk
python
respectively
pypy
python
implementation
originally
written
python
==
api
documentation
generators
==
python
api
documentation
generators
include
sphinx
epydoc
headerdoc
pydoc
==
uses
==
since
2003
python
consistently
ranked
top
ten
popular
programming
languages
tiobe
programming
community
index
february
2020
third
popular
language
behind
java
c
selected
programming
language
year
2007
2010
2018.an
empirical
study
found
scripting
languages
python
productive
conventional
languages
c
java
programming
problems
involving
string
manipulation
search
dictionary
determined
memory
consumption
often
``
better
java
much
worse
c
c++
''
.large
organizations
use
python
include
wikipedia
google
yahoo
cern
nasa
facebook
amazon
instagram
spotify
smaller
entities
like
ilm
ita
social
news
networking
site
reddit
written
entirely
python
python
serve
scripting
language
web
applications
e.g.
via
mod_wsgi
apache
web
server
web
server
gateway
interface
standard
api
evolved
facilitate
applications
web
frameworks
like
django
pylons
pyramid
turbogears
web2py
tornado
flask
bottle
zope
support
developers
design
maintenance
complex
applications
pyjs
ironpython
used
develop
client-side
ajax-based
applications
sqlalchemy
used
data
mapper
relational
database
twisted
framework
program
communications
computers
used
example
dropbox
libraries
numpy
scipy
matplotlib
allow
effective
use
python
scientific
computing
specialized
libraries
biopython
astropy
providing
domain-specific
functionality
sagemath
mathematical
software
notebook
interface
programmable
python
library
covers
many
aspects
mathematics
including
algebra
combinatorics
numerical
mathematics
number
theory
calculus
python
successfully
embedded
many
software
products
scripting
language
including
finite
element
method
software
abaqus
3d
parametric
modeler
like
freecad
3d
animation
packages
3ds
max
blender
cinema
4d
lightwave
houdini
maya
modo
motionbuilder
softimage
visual
effects
compositor
nuke
2d
imaging
programs
like
gimp
inkscape
scribus
paint
shop
pro
musical
notation
programs
like
scorewriter
capella
gnu
debugger
uses
python
pretty
printer
show
complex
structures
c++
containers
esri
promotes
python
best
choice
writing
scripts
arcgis
also
used
several
video
games
adopted
first
three
available
programming
languages
google
app
engine
two
java
go
python
commonly
used
artificial
intelligence
projects
help
libraries
like
tensorflow
keras
pytorch
scikit-learn
scripting
language
modular
architecture
simple
syntax
rich
text
processing
tools
python
often
used
natural
language
processing
many
operating
systems
include
python
standard
component
ships
linux
distributions
amigaos
4
freebsd
package
netbsd
openbsd
package
macos
used
command
line
terminal
many
linux
distributions
use
installers
written
python
ubuntu
uses
ubiquity
installer
red
hat
linux
fedora
use
anaconda
installer
gentoo
linux
uses
python
package
management
system
portage
python
used
extensively
information
security
industry
including
exploit
development
sugar
software
one
laptop
per
child
xo
developed
sugar
labs
written
python
raspberry
pi
single-board
computer
project
adopted
python
main
user-programming
language
due
python
's
user-friendly
conventions
easy-to-understand
language
commonly
used
intro
language
computing
sciences
students
allows
students
easily
learn
computing
theories
concepts
apply
programming
languages
libreoffice
includes
python
intends
replace
java
python
python
scripting
provider
core
feature
since
version
4.0
7
february
2013
==
languages
influenced
python
==
python
's
design
philosophy
influenced
many
programming
languages
boo
uses
indentation
similar
syntax
similar
object
model
cobra
uses
indentation
similar
syntax
``
acknowledgements
''
document
lists
python
first
among
languages
influenced
however
cobra
directly
supports
design-by-contract
unit
tests
optional
static
typing
coffeescript
programming
language
cross-compiles
javascript
python-inspired
syntax
ecmascript
borrowed
iterators
generators
python
go
designed
``
speed
working
dynamic
language
like
python
''
shares
syntax
slicing
arrays
groovy
motivated
desire
bring
python
design
philosophy
java
julia
designed
``
true
macros
..
usable
general
programming
python
fast
c
''
calling
julia
possible
pycall.jl
python
package
pyjulia
allows
calling
direction
python
kotlin
functional
programming
language
interactive
shell
similar
python
however
kotlin
statically
typed
access
standard
java
libraries
nim
uses
indentation
similar
syntax
however
statically
typed
offers
powerful
macros
ruby
's
creator
yukihiro
matsumoto
said
``
wanted
scripting
language
powerful
perl
object-oriented
python
's
decided
design
language
''
swift
programming
language
developed
apple
python-inspired
syntax
gdscript
dynamically
typed
programming
language
used
create
video-games
extremely
similar
python
minor
differences
python
's
development
practices
also
emulated
languages
example
practice
requiring
document
describing
rationale
issues
surrounding
change
language
python
pep
also
used
tcl
erlang
==
see
also
==
python
syntax
semantics
pip
package
manager
ipython
==
references
==
===
sources
===
''
python
artificial
intelligence
''
wiki.python.org
19
july
2012.
archived
original
1
november
2012.
retrieved
3
december
2012.
paine
jocelyn
ed
august
2005
``
ai
python
''
ai
expert
newsletter
amzi
retrieved
11
february
2012
``
pyaiml
0.8.5
python
package
index
''
pypi.python.org
retrieved
17
july
2013.
russell
stuart
j
norvig
peter
2009
artificial
intelligence
modern
approach
3rd
ed.
upper
saddle
river
nj
prentice
hall
isbn
978-0-13-604259-4
==
reading
==
downey
allen
b
may
2012
think
python
think
like
computer
scientist
version
1.6.6
ed.
isbn
978-0-521-72596-5.
hamilton
naomi
5
august
2008
``
a-z
programming
languages
python
''
computerworld
archived
original
29
december
2008.
retrieved
31
march
2010.
lutz
mark
2013
learning
python
5th
ed.
o'reilly
media
isbn
978-0-596-15806-4.
pilgrim
mark
2004
dive
python
apress
isbn
978-1-59059-356-1.
pilgrim
mark
2009
dive
python
3.
apress
isbn
978-1-4302-2415-0.
summerfield
mark
2009
programming
python
3
2nd
ed.
addison-wesley
professional
isbn
978-0-321-68056-3
==
external
links
==
official
website
python
programming
language
curlie
https
//en.wikipedia.org/wiki/natural_language_processing
natural
language
processing
nlp
subfield
linguistics
computer
science
information
engineering
artificial
intelligence
concerned
interactions
computers
human
natural
languages
particular
program
computers
process
analyze
large
amounts
natural
language
data
challenges
natural
language
processing
frequently
involve
speech
recognition
natural
language
understanding
natural
language
generation
==
history
==
history
natural
language
processing
nlp
generally
started
1950s
although
work
found
earlier
periods
1950
alan
turing
published
article
titled
``
computing
machinery
intelligence
''
proposed
called
turing
test
criterion
intelligence
georgetown
experiment
1954
involved
fully
automatic
translation
sixty
russian
sentences
english
authors
claimed
within
three
five
years
machine
translation
would
solved
problem
however
real
progress
much
slower
alpac
report
1966
found
ten-year-long
research
failed
fulfill
expectations
funding
machine
translation
dramatically
reduced
little
research
machine
translation
conducted
late
1980s
first
statistical
machine
translation
systems
developed
notably
successful
natural
language
processing
systems
developed
1960s
shrdlu
natural
language
system
working
restricted
``
blocks
worlds
''
restricted
vocabularies
eliza
simulation
rogerian
psychotherapist
written
joseph
weizenbaum
1964
1966.
using
almost
information
human
thought
emotion
eliza
sometimes
provided
startlingly
human-like
interaction
``
patient
''
exceeded
small
knowledge
base
eliza
might
provide
generic
response
example
responding
``
head
hurts
''
``
say
head
hurts
''
1970s
many
programmers
began
write
``
conceptual
ontologies
''
structured
real-world
information
computer-understandable
data
examples
margie
schank
1975
sam
cullingford
1978
pam
wilensky
1978
talespin
meehan
1976
qualm
lehnert
1977
politics
carbonell
1979
plot
units
lehnert
1981
time
many
chatterbots
written
including
parry
racter
jabberwacky
1980s
natural
language
processing
systems
based
complex
sets
hand-written
rules
starting
late
1980s
however
revolution
natural
language
processing
introduction
machine
learning
algorithms
language
processing
due
steady
increase
computational
power
see
moore
's
law
gradual
lessening
dominance
chomskyan
theories
linguistics
e.g
transformational
grammar
whose
theoretical
underpinnings
discouraged
sort
corpus
linguistics
underlies
machine-learning
approach
language
processing
earliest-used
machine
learning
algorithms
decision
trees
produced
systems
hard
if-then
rules
similar
existing
hand-written
rules
however
part-of-speech
tagging
introduced
use
hidden
markov
models
natural
language
processing
increasingly
research
focused
statistical
models
make
soft
probabilistic
decisions
based
attaching
real-valued
weights
features
making
input
data
cache
language
models
upon
many
speech
recognition
systems
rely
examples
statistical
models
models
generally
robust
given
unfamiliar
input
especially
input
contains
errors
common
real-world
data
produce
reliable
results
integrated
larger
system
comprising
multiple
subtasks
many
notable
early
successes
occurred
field
machine
translation
due
especially
work
ibm
research
successively
complicated
statistical
models
developed
systems
able
take
advantage
existing
multilingual
textual
corpora
produced
parliament
canada
european
union
result
laws
calling
translation
governmental
proceedings
official
languages
corresponding
systems
government
however
systems
depended
corpora
specifically
developed
tasks
implemented
systems
often
continues
major
limitation
success
systems
result
great
deal
research
gone
methods
effectively
learning
limited
amounts
data
recent
research
increasingly
focused
unsupervised
semi-supervised
learning
algorithms
algorithms
learn
data
hand-annotated
desired
answers
using
combination
annotated
non-annotated
data
generally
task
much
difficult
supervised
learning
typically
produces
less
accurate
results
given
amount
input
data
however
enormous
amount
non-annotated
data
available
including
among
things
entire
content
world
wide
web
often
make
inferior
results
algorithm
used
low
enough
time
complexity
practical
2010s
representation
learning
deep
neural
network-style
machine
learning
methods
became
widespread
natural
language
processing
due
part
flurry
results
showing
techniques
achieve
state-of-the-art
results
many
natural
language
tasks
example
language
modeling
parsing
many
others
popular
techniques
include
use
word
embeddings
capture
semantic
properties
words
increase
end-to-end
learning
higher-level
task
e.g.
question
answering
instead
relying
pipeline
separate
intermediate
tasks
e.g.
part-of-speech
tagging
dependency
parsing
areas
shift
entailed
substantial
changes
nlp
systems
designed
deep
neural
network-based
approaches
may
viewed
new
paradigm
distinct
statistical
natural
language
processing
instance
term
neural
machine
translation
nmt
emphasizes
fact
deep
learning-based
approaches
machine
translation
directly
learn
sequence-to-sequence
transformations
obviating
need
intermediate
steps
word
alignment
language
modeling
used
statistical
machine
translation
smt
==
rule-based
vs.
statistical
nlp
==
early
days
many
language-processing
systems
designed
hand-coding
set
rules
writing
grammars
devising
heuristic
rules
stemming
since
so-called
``
statistical
revolution
''
late
1980s
mid-1990s
much
natural
language
processing
research
relied
heavily
machine
learning
machine-learning
paradigm
calls
instead
using
statistical
inference
automatically
learn
rules
analysis
large
corpora
plural
form
corpus
set
documents
possibly
human
computer
annotations
typical
real-world
examples
many
different
classes
machine-learning
algorithms
applied
natural-language-processing
tasks
algorithms
take
input
large
set
``
features
''
generated
input
data
earliest-used
algorithms
decision
trees
produced
systems
hard
if-then
rules
similar
systems
handwritten
rules
common
increasingly
however
research
focused
statistical
models
make
soft
probabilistic
decisions
based
attaching
real-valued
weights
input
feature
models
advantage
express
relative
certainty
many
different
possible
answers
rather
one
producing
reliable
results
model
included
component
larger
system
systems
based
machine-learning
algorithms
many
advantages
hand-produced
rules
learning
procedures
used
machine
learning
automatically
focus
common
cases
whereas
writing
rules
hand
often
obvious
effort
directed
automatic
learning
procedures
make
use
statistical
inference
algorithms
produce
models
robust
unfamiliar
input
e.g
containing
words
structures
seen
erroneous
input
e.g
misspelled
words
words
accidentally
omitted
generally
handling
input
gracefully
handwritten
rules
generally
creating
systems
handwritten
rules
make
soft
decisions
extremely
difficult
error-prone
time-consuming
systems
based
automatically
learning
rules
made
accurate
simply
supplying
input
data
however
systems
based
handwritten
rules
made
accurate
increasing
complexity
rules
much
difficult
task
particular
limit
complexity
systems
based
handcrafted
rules
beyond
systems
become
unmanageable
however
creating
data
input
machine-learning
systems
simply
requires
corresponding
increase
number
man-hours
worked
generally
without
significant
increases
complexity
annotation
process
==
major
evaluations
tasks
==
following
list
commonly
researched
tasks
natural
language
processing
tasks
direct
real-world
applications
others
commonly
serve
subtasks
used
aid
solving
larger
tasks
though
natural
language
processing
tasks
closely
intertwined
frequently
subdivided
categories
convenience
coarse
division
given
===
syntax
===
grammar
induction
generate
formal
grammar
describes
language
's
syntax
lemmatization
task
removing
inflectional
endings
return
base
dictionary
form
word
also
known
lemma
morphological
segmentation
separate
words
individual
morphemes
identify
class
morphemes
difficulty
task
depends
greatly
complexity
morphology
i.e
structure
words
language
considered
english
fairly
simple
morphology
especially
inflectional
morphology
thus
often
possible
ignore
task
entirely
simply
model
possible
forms
word
e.g
``
open
opens
opened
opening
''
separate
words
languages
turkish
meitei
highly
agglutinated
indian
language
however
approach
possible
dictionary
entry
thousands
possible
word
forms
part-of-speech
tagging
given
sentence
determine
part
speech
pos
word
many
words
especially
common
ones
serve
multiple
parts
speech
example
``
book
''
noun
``
book
table
''
verb
``
book
flight
''
``
set
''
noun
verb
adjective
``
''
least
five
different
parts
speech
languages
ambiguity
others
languages
little
inflectional
morphology
english
particularly
prone
ambiguity
chinese
prone
ambiguity
tonal
language
verbalization
inflection
readily
conveyed
via
entities
employed
within
orthography
convey
intended
meaning
parsing
determine
parse
tree
grammatical
analysis
given
sentence
grammar
natural
languages
ambiguous
typical
sentences
multiple
possible
analyses
perhaps
surprisingly
typical
sentence
may
thousands
potential
parses
seem
completely
nonsensical
human
two
primary
types
parsing
dependency
parsing
constituency
parsing
dependency
parsing
focuses
relationships
words
sentence
marking
things
like
primary
objects
predicates
whereas
constituency
parsing
focuses
building
parse
tree
using
probabilistic
context-free
grammar
pcfg
see
also
stochastic
grammar
sentence
breaking
also
known
sentence
boundary
disambiguation
given
chunk
text
find
sentence
boundaries
sentence
boundaries
often
marked
periods
punctuation
marks
characters
serve
purposes
e.g
marking
abbreviations
stemming
process
reducing
inflected
sometimes
derived
words
root
form
e.g
``
close
''
root
``
closed
''
``
closing
''
``
close
''
``
closer
''
etc.
word
segmentation
separate
chunk
continuous
text
separate
words
language
like
english
fairly
trivial
since
words
usually
separated
spaces
however
written
languages
like
chinese
japanese
thai
mark
word
boundaries
fashion
languages
text
segmentation
significant
task
requiring
knowledge
vocabulary
morphology
words
language
sometimes
process
also
used
cases
like
bag
words
bow
creation
data
mining
terminology
extraction
goal
terminology
extraction
automatically
extract
relevant
terms
given
corpus
===
semantics
===
lexical
semantics
computational
meaning
individual
words
context
distributional
semantics
learn
semantic
representations
data
machine
translation
automatically
translate
text
one
human
language
another
one
difficult
problems
member
class
problems
colloquially
termed
``
ai-complete
''
i.e
requiring
different
types
knowledge
humans
possess
grammar
semantics
facts
real
world
etc
solve
properly
named
entity
recognition
ner
given
stream
text
determine
items
text
map
proper
names
people
places
type
name
e.g
person
location
organization
although
capitalization
aid
recognizing
named
entities
languages
english
information
aid
determining
type
named
entity
case
often
inaccurate
insufficient
example
first
letter
sentence
also
capitalized
named
entities
often
span
several
words
capitalized
furthermore
many
languages
non-western
scripts
e.g
chinese
arabic
capitalization
even
languages
capitalization
may
consistently
use
distinguish
names
example
german
capitalizes
nouns
regardless
whether
names
french
spanish
capitalize
names
serve
adjectives
natural
language
generation
convert
information
computer
databases
semantic
intents
readable
human
language
natural
language
understanding
convert
chunks
text
formal
representations
first-order
logic
structures
easier
computer
programs
manipulate
natural
language
understanding
involves
identification
intended
semantic
multiple
possible
semantics
derived
natural
language
expression
usually
takes
form
organized
notations
natural
language
concepts
introduction
creation
language
metamodel
ontology
efficient
however
empirical
solutions
explicit
formalization
natural
language
semantics
without
confusions
implicit
assumptions
closed-world
assumption
cwa
vs.
open-world
assumption
subjective
yes/no
vs.
objective
true/false
expected
construction
basis
semantics
formalization
optical
character
recognition
ocr
given
image
representing
printed
text
determine
corresponding
text
question
answering
given
human-language
question
determine
answer
typical
questions
specific
right
answer
``
capital
canada
``
sometimes
open-ended
questions
also
considered
``
meaning
life
''
recent
works
looked
even
complex
questions
recognizing
textual
entailment
given
two
text
fragments
determine
one
true
entails
entails
's
negation
allows
either
true
false
relationship
extraction
given
chunk
text
identify
relationships
among
named
entities
e.g
married
sentiment
analysis
see
also
multimodal
sentiment
analysis
extract
subjective
information
usually
set
documents
often
using
online
reviews
determine
``
polarity
''
specific
objects
especially
useful
identifying
trends
public
opinion
social
media
marketing
topic
segmentation
recognition
given
chunk
text
separate
segments
devoted
topic
identify
topic
segment
word
sense
disambiguation
many
words
one
meaning
select
meaning
makes
sense
context
problem
typically
given
list
words
associated
word
senses
e.g
dictionary
online
resource
wordnet
===
discourse
===
automatic
summarization
produce
readable
summary
chunk
text
often
used
provide
summaries
text
known
type
research
papers
articles
financial
section
newspaper
coreference
resolution
given
sentence
larger
chunk
text
determine
words
``
mentions
''
refer
objects
``
entities
''
anaphora
resolution
specific
example
task
specifically
concerned
matching
pronouns
nouns
names
refer
general
task
coreference
resolution
also
includes
identifying
so-called
``
bridging
relationships
''
involving
referring
expressions
example
sentence
``
entered
john
's
house
front
door
''
``
front
door
''
referring
expression
bridging
relationship
identified
fact
door
referred
front
door
john
's
house
rather
structure
might
also
referred
discourse
analysis
rubric
includes
several
related
tasks
one
task
identifying
discourse
structure
connected
text
i.e
nature
discourse
relationships
sentences
e.g
elaboration
explanation
contrast
another
possible
task
recognizing
classifying
speech
acts
chunk
text
e.g
yes-no
question
content
question
statement
assertion
etc.
===
speech
===
speech
recognition
given
sound
clip
person
people
speaking
determine
textual
representation
speech
opposite
text
speech
one
extremely
difficult
problems
colloquially
termed
``
ai-complete
''
see
natural
speech
hardly
pauses
successive
words
thus
speech
segmentation
necessary
subtask
speech
recognition
see
spoken
languages
sounds
representing
successive
letters
blend
process
termed
coarticulation
conversion
analog
signal
discrete
characters
difficult
process
also
given
words
language
spoken
people
different
accents
speech
recognition
software
must
able
recognize
wide
variety
input
identical
terms
textual
equivalent
speech
segmentation
given
sound
clip
person
people
speaking
separate
words
subtask
speech
recognition
typically
grouped
text-to-speech
given
text
transform
units
produce
spoken
representation
text-to-speech
used
aid
visually
impaired
===
dialogue
===
first
published
work
artificial
intelligence
published
2018
1
road
marketed
novel
contains
sixty
million
words
==
see
also
==
==
references
==
==
reading
==
https
//en.wikipedia.org/wiki/artificial_intelligence
computer
science
artificial
intelligence
ai
sometimes
called
machine
intelligence
intelligence
demonstrated
machines
contrast
natural
intelligence
displayed
humans
animals
leading
ai
textbooks
define
field
study
``
intelligent
agents
''
device
perceives
environment
takes
actions
maximize
chance
successfully
achieving
goals
colloquially
term
``
artificial
intelligence
''
often
used
describe
machines
computers
mimic
``
cognitive
''
functions
humans
associate
human
mind
``
learning
''
``
problem
solving
''
.as
machines
become
increasingly
capable
tasks
considered
require
``
intelligence
''
often
removed
definition
ai
phenomenon
known
ai
effect
quip
tesler
's
theorem
says
``
ai
whatever
n't
done
yet
''
instance
optical
character
recognition
frequently
excluded
things
considered
ai
become
routine
technology
modern
machine
capabilities
generally
classified
ai
include
successfully
understanding
human
speech
competing
highest
level
strategic
game
systems
chess
go
autonomously
operating
cars
intelligent
routing
content
delivery
networks
military
simulations
artificial
intelligence
founded
academic
discipline
1955
years
since
experienced
several
waves
optimism
followed
disappointment
loss
funding
known
``
ai
winter
''
followed
new
approaches
success
renewed
funding
history
ai
research
divided
subfields
often
fail
communicate
sub-fields
based
technical
considerations
particular
goals
e.g
``
robotics
''
``
machine
learning
''
use
particular
tools
``
logic
''
artificial
neural
networks
deep
philosophical
differences
subfields
also
based
social
factors
particular
institutions
work
particular
researchers
.the
traditional
problems
goals
ai
research
include
reasoning
knowledge
representation
planning
learning
natural
language
processing
perception
ability
move
manipulate
objects
general
intelligence
among
field
's
long-term
goals
approaches
include
statistical
methods
computational
intelligence
traditional
symbolic
ai
many
tools
used
ai
including
versions
search
mathematical
optimization
artificial
neural
networks
methods
based
statistics
probability
economics
ai
field
draws
upon
computer
science
information
engineering
mathematics
psychology
linguistics
philosophy
many
fields
field
founded
assumption
human
intelligence
``
precisely
described
machine
made
simulate
''
raises
philosophical
arguments
nature
mind
ethics
creating
artificial
beings
endowed
human-like
intelligence
issues
explored
myth
fiction
philosophy
since
antiquity
people
also
consider
ai
danger
humanity
progresses
unabated
others
believe
ai
unlike
previous
technological
revolutions
create
risk
mass
unemployment
twenty-first
century
ai
techniques
experienced
resurgence
following
concurrent
advances
computer
power
large
amounts
data
theoretical
understanding
ai
techniques
become
essential
part
technology
industry
helping
solve
many
challenging
problems
computer
science
software
engineering
operations
research
==
history
==
thought-capable
artificial
beings
appeared
storytelling
devices
antiquity
common
fiction
mary
shelley
's
frankenstein
karel
čapek
's
r.u.r
rossum
's
universal
robots
characters
fates
raised
many
issues
discussed
ethics
artificial
intelligence
study
mechanical
``
formal
''
reasoning
began
philosophers
mathematicians
antiquity
study
mathematical
logic
led
directly
alan
turing
's
theory
computation
suggested
machine
shuffling
symbols
simple
``
0
''
``
1
''
could
simulate
conceivable
act
mathematical
deduction
insight
digital
computers
simulate
process
formal
reasoning
known
church–turing
thesis
along
concurrent
discoveries
neurobiology
information
theory
cybernetics
led
researchers
consider
possibility
building
electronic
brain
turing
proposed
changing
question
whether
machine
intelligent
``
whether
possible
machinery
show
intelligent
behaviour
''
first
work
generally
recognized
ai
mccullouch
pitts
1943
formal
design
turing-complete
``
artificial
neurons
''
.the
field
ai
research
born
workshop
dartmouth
college
1956
term
``
artificial
intelligence
''
coined
john
mccarthy
distinguish
field
cybernetics
escape
influence
cyberneticist
norbert
wiener
attendees
allen
newell
cmu
herbert
simon
cmu
john
mccarthy
mit
marvin
minsky
mit
arthur
samuel
ibm
became
founders
leaders
ai
research
students
produced
programs
press
described
``
astonishing
''
computers
learning
checkers
strategies
c.
1954
1959
reportedly
playing
better
average
human
solving
word
problems
algebra
proving
logical
theorems
logic
theorist
first
run
c.
1956
speaking
english
middle
1960s
research
u.s.
heavily
funded
department
defense
laboratories
established
around
world
ai
's
founders
optimistic
future
herbert
simon
predicted
``
machines
capable
within
twenty
years
work
man
''
marvin
minsky
agreed
writing
``
within
generation
...
problem
creating
'artificial
intelligence
substantially
solved
''
.they
failed
recognize
difficulty
remaining
tasks
progress
slowed
1974
response
criticism
sir
james
lighthill
ongoing
pressure
us
congress
fund
productive
projects
u.s.
british
governments
cut
exploratory
research
ai
next
years
would
later
called
``
ai
winter
''
period
obtaining
funding
ai
projects
difficult
early
1980s
ai
research
revived
commercial
success
expert
systems
form
ai
program
simulated
knowledge
analytical
skills
human
experts
1985
market
ai
reached
billion
dollars
time
japan
's
fifth
generation
computer
project
inspired
u.s
british
governments
restore
funding
academic
research
however
beginning
collapse
lisp
machine
market
1987
ai
fell
disrepute
second
longer-lasting
hiatus
began
development
metal–oxide–semiconductor
mos
very-large-scale
integration
vlsi
form
complementary
mos
cmos
transistor
technology
enabled
development
practical
artificial
neural
network
ann
technology
1980s
landmark
publication
field
1989
book
analog
vlsi
implementation
neural
systems
carver
a.
mead
mohammed
ismail
late
1990s
early
21st
century
ai
began
used
logistics
data
mining
medical
diagnosis
areas
success
due
increasing
computational
power
see
moore
's
law
transistor
count
greater
emphasis
solving
specific
problems
new
ties
ai
fields
statistics
economics
mathematics
commitment
researchers
mathematical
methods
scientific
standards
deep
blue
became
first
computer
chess-playing
system
beat
reigning
world
chess
champion
garry
kasparov
11
may
1997.in
2011
jeopardy
quiz
show
exhibition
match
ibm
's
question
answering
system
watson
defeated
two
greatest
jeopardy
champions
brad
rutter
ken
jennings
significant
margin
faster
computers
algorithmic
improvements
access
large
amounts
data
enabled
advances
machine
learning
perception
data-hungry
deep
learning
methods
started
dominate
accuracy
benchmarks
around
2012.
kinect
provides
3d
body–motion
interface
xbox
360
xbox
one
uses
algorithms
emerged
lengthy
ai
research
intelligent
personal
assistants
smartphones
march
2016
alphago
4
5
games
go
match
go
champion
lee
sedol
becoming
first
computer
go-playing
system
beat
professional
go
player
without
handicaps
2017
future
go
summit
alphago
three-game
match
ke
jie
time
continuously
held
world
1
ranking
two
years
marked
completion
significant
milestone
development
artificial
intelligence
go
relatively
complex
game
chess
according
bloomberg
's
jack
clark
2015
landmark
year
artificial
intelligence
number
software
projects
use
ai
google
increased
``
sporadic
usage
''
2012
2,700
projects
clark
also
presents
factual
data
indicating
improvements
ai
since
2012
supported
lower
error
rates
image
processing
tasks
attributes
increase
affordable
neural
networks
due
rise
cloud
computing
infrastructure
increase
research
tools
datasets
cited
examples
include
microsoft
's
development
skype
system
automatically
translate
one
language
another
facebook
's
system
describe
images
blind
people
2017
survey
one
five
companies
reported
``
incorporated
ai
offerings
processes
''
around
2016
china
greatly
accelerated
government
funding
given
large
supply
data
rapidly
increasing
research
output
observers
believe
may
track
becoming
``
ai
superpower
''
however
acknowledged
reports
regarding
artificial
intelligence
tended
exaggerated
==
definitions
==
computer
science
defines
ai
research
study
``
intelligent
agents
''
device
perceives
environment
takes
actions
maximize
chance
successfully
achieving
goals
elaborate
definition
characterizes
ai
``
system
's
ability
correctly
interpret
external
data
learn
data
use
learnings
achieve
specific
goals
tasks
flexible
adaptation
''
==
basics
==
typical
ai
analyzes
environment
takes
actions
maximize
chance
success
ai
's
intended
utility
function
goal
simple
``
1
ai
wins
game
go
0
otherwise
''
complex
``
mathematically
similar
actions
ones
succeeded
past
''
goals
explicitly
defined
induced
ai
programmed
``
reinforcement
learning
''
goals
implicitly
induced
rewarding
types
behavior
punishing
others
alternatively
evolutionary
system
induce
goals
using
``
fitness
function
''
mutate
preferentially
replicate
high-scoring
ai
systems
similar
animals
evolved
innately
desire
certain
goals
finding
food
ai
systems
nearest-neighbor
instead
reason
analogy
systems
generally
given
goals
except
degree
goals
implicit
training
data
systems
still
benchmarked
non-goal
system
framed
system
whose
``
goal
''
successfully
accomplish
narrow
classification
task
ai
often
revolves
around
use
algorithms
algorithm
set
unambiguous
instructions
mechanical
computer
execute
complex
algorithm
often
built
top
simpler
algorithms
simple
example
algorithm
following
optimal
first
player
recipe
play
tic-tac-toe
someone
``
threat
''
two
row
take
remaining
square
otherwise
move
``
forks
''
create
two
threats
play
move
otherwise
take
center
square
free
otherwise
opponent
played
corner
take
opposite
corner
otherwise
take
empty
corner
one
exists
otherwise
take
empty
square
many
ai
algorithms
capable
learning
data
enhance
learning
new
heuristics
strategies
``
rules
thumb
''
worked
well
past
write
algorithms
``
learners
''
described
including
bayesian
networks
decision
trees
nearest-neighbor
could
theoretically
given
infinite
data
time
memory
learn
approximate
function
including
combination
mathematical
functions
would
best
describe
world
learners
could
therefore
derive
possible
knowledge
considering
every
possible
hypothesis
matching
data
practice
almost
never
possible
consider
every
possibility
phenomenon
``
combinatorial
explosion
''
amount
time
needed
solve
problem
grows
exponentially
much
ai
research
involves
figuring
identify
avoid
considering
broad
range
possibilities
unlikely
beneficial
example
viewing
map
looking
shortest
driving
route
denver
new
york
east
one
cases
skip
looking
path
san
francisco
areas
far
west
thus
ai
wielding
pathfinding
algorithm
like
avoid
combinatorial
explosion
would
ensue
every
possible
route
ponderously
considered
turn
earliest
easiest
understand
approach
ai
symbolism
formal
logic
``
otherwise
healthy
adult
fever
may
influenza
''
second
general
approach
bayesian
inference
``
current
patient
fever
adjust
probability
influenza
such-and-such
way
''
third
major
approach
extremely
popular
routine
business
ai
applications
analogizers
svm
nearest-neighbor
``
examining
records
known
past
patients
whose
temperature
symptoms
age
factors
mostly
match
current
patient
x
patients
turned
influenza
''
fourth
approach
harder
intuitively
understand
inspired
brain
's
machinery
works
artificial
neural
network
approach
uses
artificial
``
neurons
''
learn
comparing
desired
output
altering
strengths
connections
internal
neurons
``
reinforce
''
connections
seemed
useful
four
main
approaches
overlap
evolutionary
systems
example
neural
nets
learn
make
inferences
generalize
make
analogies
systems
implicitly
explicitly
use
multiple
approaches
alongside
many
ai
non-ai
algorithms
best
approach
often
different
depending
problem
learning
algorithms
work
basis
strategies
algorithms
inferences
worked
well
past
likely
continue
working
well
future
inferences
obvious
``
since
sun
rose
every
morning
last
10,000
days
probably
rise
tomorrow
morning
well
''
nuanced
``
x
families
geographically
separate
species
color
variants
chance
undiscovered
black
swans
exist
''
learners
also
work
basis
``
occam
's
razor
''
simplest
theory
explains
data
likeliest
therefore
according
occam
's
razor
principle
learner
must
designed
prefers
simpler
theories
complex
theories
except
cases
complex
theory
proven
substantially
better
settling
bad
overly
complex
theory
gerrymandered
fit
past
training
data
known
overfitting
many
systems
attempt
reduce
overfitting
rewarding
theory
accordance
well
fits
data
penalizing
theory
accordance
complex
theory
besides
classic
overfitting
learners
also
disappoint
``
learning
wrong
lesson
''
toy
example
image
classifier
trained
pictures
brown
horses
black
cats
might
conclude
brown
patches
likely
horses
real-world
example
unlike
humans
current
image
classifiers
n't
determine
spatial
relationship
components
picture
instead
learn
abstract
patterns
pixels
humans
oblivious
linearly
correlate
images
certain
types
real
objects
faintly
superimposing
pattern
legitimate
image
results
``
adversarial
''
image
system
misclassifies
compared
humans
existing
ai
lacks
several
features
human
``
commonsense
reasoning
''
notably
humans
powerful
mechanisms
reasoning
``
naïve
physics
''
space
time
physical
interactions
enables
even
young
children
easily
make
inferences
like
``
roll
pen
table
fall
floor
''
humans
also
powerful
mechanism
``
folk
psychology
''
helps
interpret
natural-language
sentences
``
city
councilmen
refused
demonstrators
permit
advocated
violence
''
generic
ai
difficulty
discerning
whether
ones
alleged
advocating
violence
councilmen
demonstrators
lack
``
common
knowledge
''
means
ai
often
makes
different
mistakes
humans
make
ways
seem
incomprehensible
example
existing
self-driving
cars
reason
location
intentions
pedestrians
exact
way
humans
instead
must
use
non-human
modes
reasoning
avoid
accidents
==
challenges
==
cognitive
capabilities
current
architectures
limited
using
simplified
version
intelligence
really
capable
instance
human
mind
come
ways
reason
beyond
measure
logical
explanations
different
occurrences
life
would
otherwise
straightforward
equivalently
difficult
problem
may
challenging
solve
computationally
opposed
using
human
mind
gives
rise
two
classes
models
structuralist
functionalist
structural
models
aim
loosely
mimic
basic
intelligence
operations
mind
reasoning
logic
functional
model
refers
correlating
data
computed
counterpart
overall
research
goal
artificial
intelligence
create
technology
allows
computers
machines
function
intelligent
manner
general
problem
simulating
creating
intelligence
broken
sub-problems
consist
particular
traits
capabilities
researchers
expect
intelligent
system
display
traits
described
received
attention
===
reasoning
problem
solving
===
early
researchers
developed
algorithms
imitated
step-by-step
reasoning
humans
use
solve
puzzles
make
logical
deductions
late
1980s
1990s
ai
research
developed
methods
dealing
uncertain
incomplete
information
employing
concepts
probability
economics
algorithms
proved
insufficient
solving
large
reasoning
problems
experienced
``
combinatorial
explosion
''
became
exponentially
slower
problems
grew
larger
fact
even
humans
rarely
use
step-by-step
deduction
early
ai
research
able
model
solve
problems
using
fast
intuitive
judgments
===
knowledge
representation
===
knowledge
representation
knowledge
engineering
central
classical
ai
research
``
expert
systems
''
attempt
gather
together
explicit
knowledge
possessed
experts
narrow
domain
addition
projects
attempt
gather
``
commonsense
knowledge
''
known
average
person
database
containing
extensive
knowledge
world
among
things
comprehensive
commonsense
knowledge
base
would
contain
objects
properties
categories
relations
objects
situations
events
states
time
causes
effects
knowledge
knowledge
know
people
know
many
less
well
researched
domains
representation
``
exists
''
ontology
set
objects
relations
concepts
properties
formally
described
software
agents
interpret
semantics
captured
description
logic
concepts
roles
individuals
typically
implemented
classes
properties
individuals
web
ontology
language
general
ontologies
called
upper
ontologies
attempt
provide
foundation
knowledge
acting
mediators
domain
ontologies
cover
specific
knowledge
particular
knowledge
domain
field
interest
area
concern
formal
knowledge
representations
used
content-based
indexing
retrieval
scene
interpretation
clinical
decision
support
knowledge
discovery
mining
``
interesting
''
actionable
inferences
large
databases
areas
among
difficult
problems
knowledge
representation
default
reasoning
qualification
problem
many
things
people
know
take
form
``
working
assumptions
''
example
bird
comes
conversation
people
typically
picture
animal
fist-sized
sings
flies
none
things
true
birds
john
mccarthy
identified
problem
1969
qualification
problem
commonsense
rule
ai
researchers
care
represent
tend
huge
number
exceptions
almost
nothing
simply
true
false
way
abstract
logic
requires
ai
research
explored
number
solutions
problem
breadth
commonsense
knowledge
number
atomic
facts
average
person
knows
large
research
projects
attempt
build
complete
knowledge
base
commonsense
knowledge
e.g.
cyc
require
enormous
amounts
laborious
ontological
engineering—they
must
built
hand
one
complicated
concept
time
subsymbolic
form
commonsense
knowledge
much
people
know
represented
``
facts
''
``
statements
''
could
express
verbally
example
chess
master
avoid
particular
chess
position
``
feels
exposed
''
art
critic
take
one
look
statue
realize
fake
non-conscious
sub-symbolic
intuitions
tendencies
human
brain
knowledge
like
informs
supports
provides
context
symbolic
conscious
knowledge
related
problem
sub-symbolic
reasoning
hoped
situated
ai
computational
intelligence
statistical
ai
provide
ways
represent
kind
knowledge
===
planning
===
intelligent
agents
must
able
set
goals
achieve
need
way
visualize
future—a
representation
state
world
able
make
predictions
actions
change
it—and
able
make
choices
maximize
utility
``
value
''
available
choices
classical
planning
problems
agent
assume
system
acting
world
allowing
agent
certain
consequences
actions
however
agent
actor
requires
agent
reason
uncertainty
calls
agent
assess
environment
make
predictions
also
evaluate
predictions
adapt
based
assessment
multi-agent
planning
uses
cooperation
competition
many
agents
achieve
given
goal
emergent
behavior
used
evolutionary
algorithms
swarm
intelligence
===
learning
===
machine
learning
ml
fundamental
concept
ai
research
since
field
's
inception
study
computer
algorithms
improve
automatically
experience
unsupervised
learning
ability
find
patterns
stream
input
without
requiring
human
label
inputs
first
supervised
learning
includes
classification
numerical
regression
requires
human
label
input
data
first
classification
used
determine
category
something
belongs
occurs
program
sees
number
examples
things
several
categories
regression
attempt
produce
function
describes
relationship
inputs
outputs
predicts
outputs
change
inputs
change
classifiers
regression
learners
viewed
``
function
approximators
''
trying
learn
unknown
possibly
implicit
function
example
spam
classifier
viewed
learning
function
maps
text
email
one
two
categories
``
spam
''
``
spam
''
computational
learning
theory
assess
learners
computational
complexity
sample
complexity
much
data
required
notions
optimization
reinforcement
learning
agent
rewarded
good
responses
punished
bad
ones
agent
uses
sequence
rewards
punishments
form
strategy
operating
problem
space
===
natural
language
processing
===
natural
language
processing
nlp
gives
machines
ability
read
understand
human
language
sufficiently
powerful
natural
language
processing
system
would
enable
natural-language
user
interfaces
acquisition
knowledge
directly
human-written
sources
newswire
texts
straightforward
applications
natural
language
processing
include
information
retrieval
text
mining
question
answering
machine
translation
many
current
approaches
use
word
co-occurrence
frequencies
construct
syntactic
representations
text
``
keyword
spotting
''
strategies
search
popular
scalable
dumb
search
query
``
dog
''
might
match
documents
literal
word
``
dog
''
miss
document
word
``
poodle
''
``
lexical
affinity
''
strategies
use
occurrence
words
``
accident
''
assess
sentiment
document
modern
statistical
nlp
approaches
combine
strategies
well
others
often
achieve
acceptable
accuracy
page
paragraph
level
continue
lack
semantic
understanding
required
classify
isolated
sentences
well
besides
usual
difficulties
encoding
semantic
commonsense
knowledge
existing
semantic
nlp
sometimes
scales
poorly
viable
business
applications
beyond
semantic
nlp
ultimate
goal
``
narrative
''
nlp
embody
full
understanding
commonsense
reasoning
===
perception
===
machine
perception
ability
use
input
sensors
cameras
visible
spectrum
infrared
microphones
wireless
signals
active
lidar
sonar
radar
tactile
sensors
deduce
aspects
world
applications
include
speech
recognition
facial
recognition
object
recognition
computer
vision
ability
analyze
visual
input
input
usually
ambiguous
giant
fifty-meter-tall
pedestrian
far
away
may
produce
exactly
pixels
nearby
normal-sized
pedestrian
requiring
ai
judge
relative
likelihood
reasonableness
different
interpretations
example
using
``
object
model
''
assess
fifty-meter
pedestrians
exist
===
motion
manipulation
===
ai
heavily
used
robotics
advanced
robotic
arms
industrial
robots
widely
used
modern
factories
learn
experience
move
efficiently
despite
presence
friction
gear
slippage
modern
mobile
robot
given
small
static
visible
environment
easily
determine
location
map
environment
however
dynamic
environments
endoscopy
interior
patient
's
breathing
body
pose
greater
challenge
motion
planning
process
breaking
movement
task
``
primitives
''
individual
joint
movements
movement
often
involves
compliant
motion
process
movement
requires
maintaining
physical
contact
object
moravec
's
paradox
generalizes
low-level
sensorimotor
skills
humans
take
granted
counterintuitively
difficult
program
robot
paradox
named
hans
moravec
stated
1988
``
comparatively
easy
make
computers
exhibit
adult
level
performance
intelligence
tests
playing
checkers
difficult
impossible
give
skills
one-year-old
comes
perception
mobility
''
attributed
fact
unlike
checkers
physical
dexterity
direct
target
natural
selection
millions
years
===
social
intelligence
===
moravec
's
paradox
extended
many
forms
social
intelligence
distributed
multi-agent
coordination
autonomous
vehicles
remains
difficult
problem
affective
computing
interdisciplinary
umbrella
comprises
systems
recognize
interpret
process
simulate
human
affects
moderate
successes
related
affective
computing
include
textual
sentiment
analysis
recently
multimodal
affect
analysis
see
multimodal
sentiment
analysis
wherein
ai
classifies
affects
displayed
videotaped
subject
long
run
social
skills
understanding
human
emotion
game
theory
would
valuable
social
agent
able
predict
actions
others
understanding
motives
emotional
states
would
allow
agent
make
better
decisions
computer
systems
mimic
human
emotion
expressions
appear
sensitive
emotional
dynamics
human
interaction
otherwise
facilitate
human–computer
interaction
similarly
virtual
assistants
programmed
speak
conversationally
even
banter
humorously
tends
give
naïve
users
unrealistic
conception
intelligent
existing
computer
agents
actually
===
general
intelligence
===
historically
projects
cyc
knowledge
base
1984–
massive
japanese
fifth
generation
computer
systems
initiative
1982–1992
attempted
cover
breadth
human
cognition
early
projects
failed
escape
limitations
non-quantitative
symbolic
logic
models
retrospect
greatly
underestimated
difficulty
cross-domain
ai
nowadays
vast
majority
current
ai
researchers
work
instead
tractable
``
narrow
ai
''
applications
medical
diagnosis
automobile
navigation
many
researchers
predict
``
narrow
ai
''
work
different
individual
domains
eventually
incorporated
machine
artificial
general
intelligence
agi
combining
narrow
skills
mentioned
article
point
even
exceeding
human
ability
areas
many
advances
general
cross-domain
significance
one
high-profile
example
deepmind
2010s
developed
``
generalized
artificial
intelligence
''
could
learn
many
diverse
atari
games
later
developed
variant
system
succeeds
sequential
learning
besides
transfer
learning
hypothetical
agi
breakthroughs
could
include
development
reflective
architectures
engage
decision-theoretic
metareasoning
figuring
``
slurp
''
comprehensive
knowledge
base
entire
unstructured
web
argue
kind
currently-undiscovered
conceptually
straightforward
mathematically
difficult
``
master
algorithm
''
could
lead
agi
finally
``
emergent
''
approaches
look
simulating
human
intelligence
extremely
closely
believe
anthropomorphic
features
like
artificial
brain
simulated
child
development
may
someday
reach
critical
point
general
intelligence
emerges
many
problems
article
may
also
require
general
intelligence
machines
solve
problems
well
people
example
even
specific
straightforward
tasks
like
machine
translation
require
machine
read
write
languages
nlp
follow
author
's
argument
reason
know
talked
knowledge
faithfully
reproduce
author
's
original
intent
social
intelligence
problem
like
machine
translation
considered
``
ai-complete
''
problems
need
solved
simultaneously
order
reach
human-level
machine
performance
==
approaches
==
established
unifying
theory
paradigm
guides
ai
research
researchers
disagree
many
issues
long
standing
questions
remained
unanswered
artificial
intelligence
simulate
natural
intelligence
studying
psychology
neurobiology
human
biology
irrelevant
ai
research
bird
biology
aeronautical
engineering
intelligent
behavior
described
using
simple
elegant
principles
logic
optimization
necessarily
require
solving
large
number
completely
unrelated
problems
===
cybernetics
brain
simulation
===
1940s
1950s
number
researchers
explored
connection
neurobiology
information
theory
cybernetics
built
machines
used
electronic
networks
exhibit
rudimentary
intelligence
w.
grey
walter
's
turtles
johns
hopkins
beast
many
researchers
gathered
meetings
teleological
society
princeton
university
ratio
club
england
1960
approach
largely
abandoned
although
elements
would
revived
1980s
===
symbolic
===
access
digital
computers
became
possible
mid-1950s
ai
research
began
explore
possibility
human
intelligence
could
reduced
symbol
manipulation
research
centered
three
institutions
carnegie
mellon
university
stanford
mit
described
one
developed
style
research
john
haugeland
named
symbolic
approaches
ai
``
good
old
fashioned
ai
''
``
gofai
''
1960s
symbolic
approaches
achieved
great
success
simulating
high-level
``
thinking
''
small
demonstration
programs
approaches
based
cybernetics
artificial
neural
networks
abandoned
pushed
background
researchers
1960s
1970s
convinced
symbolic
approaches
would
eventually
succeed
creating
machine
artificial
general
intelligence
considered
goal
field
====
cognitive
simulation
====
economist
herbert
simon
allen
newell
studied
human
problem-solving
skills
attempted
formalize
work
laid
foundations
field
artificial
intelligence
well
cognitive
science
operations
research
management
science
research
team
used
results
psychological
experiments
develop
programs
simulated
techniques
people
used
solve
problems
tradition
centered
carnegie
mellon
university
would
eventually
culminate
development
soar
architecture
middle
1980s
====
logic-based
====
unlike
simon
newell
john
mccarthy
felt
machines
need
simulate
human
thought
instead
try
find
essence
abstract
reasoning
problem-solving
regardless
whether
people
used
algorithms
laboratory
stanford
sail
focused
using
formal
logic
solve
wide
variety
problems
including
knowledge
representation
planning
learning
logic
also
focus
work
university
edinburgh
elsewhere
europe
led
development
programming
language
prolog
science
logic
programming
====
anti-logic
scruffy
====
researchers
mit
marvin
minsky
seymour
papert
found
solving
difficult
problems
vision
natural
language
processing
required
ad-hoc
solutions—they
argued
simple
general
principle
like
logic
would
capture
aspects
intelligent
behavior
roger
schank
described
``
anti-logic
''
approaches
``
scruffy
''
opposed
``
neat
''
paradigms
cmu
stanford
commonsense
knowledge
bases
doug
lenat
's
cyc
example
``
scruffy
''
ai
since
must
built
hand
one
complicated
concept
time
====
knowledge-based
====
computers
large
memories
became
available
around
1970
researchers
three
traditions
began
build
knowledge
ai
applications
``
knowledge
revolution
''
led
development
deployment
expert
systems
introduced
edward
feigenbaum
first
truly
successful
form
ai
software
key
component
system
architecture
expert
systems
knowledge
base
stores
facts
rules
illustrate
ai
knowledge
revolution
also
driven
realization
enormous
amounts
knowledge
would
required
many
simple
ai
applications
===
sub-symbolic
===
1980s
progress
symbolic
ai
seemed
stall
many
believed
symbolic
systems
would
never
able
imitate
processes
human
cognition
especially
perception
robotics
learning
pattern
recognition
number
researchers
began
look
``
sub-symbolic
''
approaches
specific
ai
problems
sub-symbolic
methods
manage
approach
intelligence
without
specific
representations
knowledge
====
embodied
intelligence
====
includes
embodied
situated
behavior-based
nouvelle
ai
researchers
related
field
robotics
rodney
brooks
rejected
symbolic
ai
focused
basic
engineering
problems
would
allow
robots
move
survive
work
revived
non-symbolic
point
view
early
cybernetics
researchers
1950s
reintroduced
use
control
theory
ai
coincided
development
embodied
mind
thesis
related
field
cognitive
science
idea
aspects
body
movement
perception
visualization
required
higher
intelligence
within
developmental
robotics
developmental
learning
approaches
elaborated
upon
allow
robots
accumulate
repertoires
novel
skills
autonomous
self-exploration
social
interaction
human
teachers
use
guidance
mechanisms
active
learning
maturation
motor
synergies
etc.
====
computational
intelligence
soft
computing
====
interest
neural
networks
``
connectionism
''
revived
david
rumelhart
others
middle
1980s
artificial
neural
networks
example
soft
computing—they
solutions
problems
solved
complete
logical
certainty
approximate
solution
often
sufficient
soft
computing
approaches
ai
include
fuzzy
systems
grey
system
theory
evolutionary
computation
many
statistical
tools
application
soft
computing
ai
studied
collectively
emerging
discipline
computational
intelligence
===
statistical
learning
===
much
traditional
gofai
got
bogged
ad
hoc
patches
symbolic
computation
worked
toy
models
failed
generalize
real-world
results
however
around
1990s
ai
researchers
adopted
sophisticated
mathematical
tools
hidden
markov
models
hmm
information
theory
normative
bayesian
decision
theory
compare
unify
competing
architectures
shared
mathematical
language
permitted
high
level
collaboration
established
fields
like
mathematics
economics
operations
research
compared
gofai
new
``
statistical
learning
''
techniques
hmm
neural
networks
gaining
higher
levels
accuracy
many
practical
domains
data
mining
without
necessarily
acquiring
semantic
understanding
datasets
increased
successes
real-world
data
led
increasing
emphasis
comparing
different
approaches
shared
test
data
see
approach
performed
best
broader
context
provided
idiosyncratic
toy
models
ai
research
becoming
scientific
nowadays
results
experiments
often
rigorously
measurable
sometimes
difficulty
reproducible
different
statistical
learning
techniques
different
limitations
example
basic
hmm
model
infinite
possible
combinations
natural
language
critics
note
shift
gofai
statistical
learning
often
also
shift
away
explainable
ai
agi
research
scholars
caution
over-reliance
statistical
learning
argue
continuing
research
gofai
still
necessary
attain
general
intelligence
===
integrating
approaches
===
intelligent
agent
paradigm
intelligent
agent
system
perceives
environment
takes
actions
maximize
chances
success
simplest
intelligent
agents
programs
solve
specific
problems
complicated
agents
include
human
beings
organizations
human
beings
firms
paradigm
allows
researchers
directly
compare
even
combine
different
approaches
isolated
problems
asking
agent
best
maximizing
given
``
goal
function
''
agent
solves
specific
problem
use
approach
works—some
agents
symbolic
logical
sub-symbolic
artificial
neural
networks
others
may
use
new
approaches
paradigm
also
gives
researchers
common
language
communicate
fields—such
decision
theory
economics—that
also
use
concepts
abstract
agents
building
complete
agent
requires
researchers
address
realistic
problems
integration
example
sensory
systems
give
uncertain
information
environment
planning
systems
must
able
function
presence
uncertainty
intelligent
agent
paradigm
became
widely
accepted
1990s
agent
architectures
cognitive
architectures
researchers
designed
systems
build
intelligent
systems
interacting
intelligent
agents
multi-agent
system
hierarchical
control
system
provides
bridge
sub-symbolic
ai
lowest
reactive
levels
traditional
symbolic
ai
highest
levels
relaxed
time
constraints
permit
planning
world
modeling
cognitive
architectures
custom-built
solve
narrow
problem
others
soar
designed
mimic
human
cognition
provide
insight
general
intelligence
modern
extensions
soar
hybrid
intelligent
systems
include
symbolic
sub-symbolic
components
==
tools
==
ai
developed
many
tools
solve
difficult
problems
computer
science
general
methods
discussed
===
search
optimization
===
many
problems
ai
solved
theory
intelligently
searching
many
possible
solutions
reasoning
reduced
performing
search
example
logical
proof
viewed
searching
path
leads
premises
conclusions
step
application
inference
rule
planning
algorithms
search
trees
goals
subgoals
attempting
find
path
target
goal
process
called
means-ends
analysis
robotics
algorithms
moving
limbs
grasping
objects
use
local
searches
configuration
space
many
learning
algorithms
use
search
algorithms
based
optimization
simple
exhaustive
searches
rarely
sufficient
real-world
problems
search
space
number
places
search
quickly
grows
astronomical
numbers
result
search
slow
never
completes
solution
many
problems
use
``
heuristics
''
``
rules
thumb
''
prioritize
choices
favor
likely
reach
goal
shorter
number
steps
search
methodologies
heuristics
also
serve
entirely
eliminate
choices
unlikely
lead
goal
called
``
pruning
search
tree
''
heuristics
supply
program
``
best
guess
''
path
solution
lies
heuristics
limit
search
solutions
smaller
sample
size
different
kind
search
came
prominence
1990s
based
mathematical
theory
optimization
many
problems
possible
begin
search
form
guess
refine
guess
incrementally
refinements
made
algorithms
visualized
blind
hill
climbing
begin
search
random
point
landscape
jumps
steps
keep
moving
guess
uphill
reach
top
optimization
algorithms
simulated
annealing
beam
search
random
optimization
evolutionary
computation
uses
form
optimization
search
example
may
begin
population
organisms
guesses
allow
mutate
recombine
selecting
fittest
survive
generation
refining
guesses
classic
evolutionary
algorithms
include
genetic
algorithms
gene
expression
programming
genetic
programming
alternatively
distributed
search
processes
coordinate
via
swarm
intelligence
algorithms
two
popular
swarm
algorithms
used
search
particle
swarm
optimization
inspired
bird
flocking
ant
colony
optimization
inspired
ant
trails
===
logic
===
logic
used
knowledge
representation
problem
solving
applied
problems
well
example
satplan
algorithm
uses
logic
planning
inductive
logic
programming
method
learning
several
different
forms
logic
used
ai
research
propositional
logic
involves
truth
functions
``
''
``
''
first-order
logic
adds
quantifiers
predicates
express
facts
objects
properties
relations
fuzzy
set
theory
assigns
``
degree
truth
''
0
1
vague
statements
``
alice
old
''
rich
tall
hungry
linguistically
imprecise
completely
true
false
fuzzy
logic
successfully
used
control
systems
allow
experts
contribute
vague
rules
``
close
destination
station
moving
fast
increase
train
's
brake
pressure
''
vague
rules
numerically
refined
within
system
fuzzy
logic
fails
scale
well
knowledge
bases
many
ai
researchers
question
validity
chaining
fuzzy-logic
inferences
default
logics
non-monotonic
logics
circumscription
forms
logic
designed
help
default
reasoning
qualification
problem
several
extensions
logic
designed
handle
specific
domains
knowledge
description
logics
situation
calculus
event
calculus
fluent
calculus
representing
events
time
causal
calculus
belief
calculus
belief
revision
modal
logics
logics
model
contradictory
inconsistent
statements
arising
multi-agent
systems
also
designed
paraconsistent
logics
===
probabilistic
methods
uncertain
reasoning
===
many
problems
ai
reasoning
planning
learning
perception
robotics
require
agent
operate
incomplete
uncertain
information
ai
researchers
devised
number
powerful
tools
solve
problems
using
methods
probability
theory
economics
bayesian
networks
general
tool
used
various
problems
reasoning
using
bayesian
inference
algorithm
learning
using
expectation-maximization
algorithm
planning
using
decision
networks
perception
using
dynamic
bayesian
networks
probabilistic
algorithms
also
used
filtering
prediction
smoothing
finding
explanations
streams
data
helping
perception
systems
analyze
processes
occur
time
e.g.
hidden
markov
models
kalman
filters
compared
symbolic
logic
formal
bayesian
inference
computationally
expensive
inference
tractable
observations
must
conditionally
independent
one
another
complicated
graphs
diamonds
``
loops
''
undirected
cycles
require
sophisticated
method
markov
chain
monte
carlo
spreads
ensemble
random
walkers
throughout
bayesian
network
attempts
converge
assessment
conditional
probabilities
bayesian
networks
used
xbox
live
rate
match
players
wins
losses
``
evidence
''
good
player
adsense
uses
bayesian
network
300
million
edges
learn
ads
serve
key
concept
science
economics
``
utility
''
measure
valuable
something
intelligent
agent
precise
mathematical
tools
developed
analyze
agent
make
choices
plan
using
decision
theory
decision
analysis
information
value
theory
tools
include
models
markov
decision
processes
dynamic
decision
networks
game
theory
mechanism
design
===
classifiers
statistical
learning
methods
===
simplest
ai
applications
divided
two
types
classifiers
``
shiny
diamond
''
controllers
``
shiny
pick
''
controllers
however
also
classify
conditions
inferring
actions
therefore
classification
forms
central
part
many
ai
systems
classifiers
functions
use
pattern
matching
determine
closest
match
tuned
according
examples
making
attractive
use
ai
examples
known
observations
patterns
supervised
learning
pattern
belongs
certain
predefined
class
class
seen
decision
made
observations
combined
class
labels
known
data
set
new
observation
received
observation
classified
based
previous
experience
classifier
trained
various
ways
many
statistical
machine
learning
approaches
decision
tree
perhaps
widely
used
machine
learning
algorithm
widely
used
classifiers
neural
network
k-nearest
neighbor
algorithm
kernel
methods
support
vector
machine
svm
gaussian
mixture
model
extremely
popular
naive
bayes
classifier
classifier
performance
depends
greatly
characteristics
data
classified
dataset
size
distribution
samples
across
classes
dimensionality
level
noise
model-based
classifiers
perform
well
assumed
model
extremely
good
fit
actual
data
otherwise
matching
model
available
accuracy
rather
speed
scalability
sole
concern
conventional
wisdom
discriminative
classifiers
especially
svm
tend
accurate
model-based
classifiers
``
naive
bayes
''
practical
data
sets
===
artificial
neural
networks
===
neural
networks
inspired
architecture
neurons
human
brain
simple
``
neuron
''
n
accepts
input
neurons
activated
``
fired
''
cast
weighted
``
vote
''
whether
neuron
n
activate
learning
requires
algorithm
adjust
weights
based
training
data
one
simple
algorithm
dubbed
``
fire
together
wire
together
''
increase
weight
two
connected
neurons
activation
one
triggers
successful
activation
another
neural
network
forms
``
concepts
''
distributed
among
subnetwork
shared
neurons
tend
fire
together
concept
meaning
``
leg
''
might
coupled
subnetwork
meaning
``
foot
''
includes
sound
``
foot
''
neurons
continuous
spectrum
activation
addition
neurons
process
inputs
nonlinear
way
rather
weighing
straightforward
votes
modern
neural
networks
learn
continuous
functions
surprisingly
digital
logical
operations
neural
networks
early
successes
included
predicting
stock
market
1995
mostly
self-driving
car
2010s
advances
neural
networks
using
deep
learning
thrust
ai
widespread
public
consciousness
contributed
enormous
upshift
corporate
ai
spending
example
ai-related
2017
25
times
large
2015.the
study
non-learning
artificial
neural
networks
began
decade
field
ai
research
founded
work
walter
pitts
warren
mccullouch
frank
rosenblatt
invented
perceptron
learning
network
single
layer
similar
old
concept
linear
regression
early
pioneers
also
include
alexey
grigorevich
ivakhnenko
teuvo
kohonen
stephen
grossberg
kunihiko
fukushima
christoph
von
der
malsburg
david
willshaw
shun-ichi
amari
bernard
widrow
john
hopfield
eduardo
r.
caianiello
others
main
categories
networks
acyclic
feedforward
neural
networks
signal
passes
one
direction
recurrent
neural
networks
allow
feedback
short-term
memories
previous
input
events
among
popular
feedforward
networks
perceptrons
multi-layer
perceptrons
radial
basis
networks
neural
networks
applied
problem
intelligent
control
robotics
learning
using
techniques
hebbian
learning
``
fire
together
wire
together
''
gmdh
competitive
learning
today
neural
networks
often
trained
backpropagation
algorithm
around
since
1970
reverse
mode
automatic
differentiation
published
seppo
linnainmaa
introduced
neural
networks
paul
werbos
hierarchical
temporal
memory
approach
models
structural
algorithmic
properties
neocortex
summarize
neural
networks
use
form
gradient
descent
hand-created
neural
topology
however
research
groups
uber
argue
simple
neuroevolution
mutate
new
neural
network
topologies
weights
may
competitive
sophisticated
gradient
descent
approaches
one
advantage
neuroevolution
may
less
prone
get
caught
``
dead
ends
''
====
deep
feedforward
neural
networks
====
deep
learning
artificial
neural
network
learn
long
chain
causal
links
example
feedforward
network
six
hidden
layers
learn
seven-link
causal
chain
six
hidden
layers
output
layer
``
credit
assignment
path
''
cap
depth
seven
many
deep
learning
systems
need
able
learn
chains
ten
causal
links
length
deep
learning
transformed
many
important
subfields
artificial
intelligence
including
computer
vision
speech
recognition
natural
language
processing
others
according
one
overview
expression
``
deep
learning
''
introduced
machine
learning
community
rina
dechter
1986
gained
traction
igor
aizenberg
colleagues
introduced
artificial
neural
networks
2000.
first
functional
deep
learning
networks
published
alexey
grigorevich
ivakhnenko
v.
g.
lapa
1965.
networks
trained
one
layer
time
ivakhnenko
's
1971
paper
describes
learning
deep
feedforward
multilayer
perceptron
eight
layers
already
much
deeper
many
later
networks
2006
publication
geoffrey
hinton
ruslan
salakhutdinov
introduced
another
way
pre-training
many-layered
feedforward
neural
networks
fnns
one
layer
time
treating
layer
turn
unsupervised
restricted
boltzmann
machine
using
supervised
backpropagation
fine-tuning
similar
shallow
artificial
neural
networks
deep
neural
networks
model
complex
non-linear
relationships
last
years
advances
machine
learning
algorithms
computer
hardware
led
efficient
methods
training
deep
neural
networks
contain
many
layers
non-linear
hidden
units
large
output
layer
deep
learning
often
uses
convolutional
neural
networks
cnns
whose
origins
traced
back
neocognitron
introduced
kunihiko
fukushima
1980.
1989
yann
lecun
colleagues
applied
backpropagation
architecture
early
2000s
industrial
application
cnns
already
processed
estimated
10
20
checks
written
us
since
2011
fast
implementations
cnns
gpus
many
visual
pattern
recognition
competitions
cnns
12
convolutional
layers
used
conjunction
reinforcement
learning
deepmind
's
``
alphago
lee
''
program
beat
top
go
champion
2016
====
deep
recurrent
neural
networks
====
early
deep
learning
also
applied
sequence
learning
recurrent
neural
networks
rnns
theory
turing
complete
run
arbitrary
programs
process
arbitrary
sequences
inputs
depth
rnn
unlimited
depends
length
input
sequence
thus
rnn
example
deep
learning
rnns
trained
gradient
descent
suffer
vanishing
gradient
problem
1992
shown
unsupervised
pre-training
stack
recurrent
neural
networks
speed
subsequent
supervised
learning
deep
sequential
problems
numerous
researchers
use
variants
deep
learning
recurrent
nn
called
long
short-term
memory
lstm
network
published
hochreiter
schmidhuber
1997.
lstm
often
trained
connectionist
temporal
classification
ctc
google
microsoft
baidu
approach
revolutionized
speech
recognition
example
2015
google
's
speech
recognition
experienced
dramatic
performance
jump
49
ctc-trained
lstm
available
google
voice
billions
smartphone
users
google
also
used
lstm
improve
machine
translation
language
modeling
multilingual
language
processing
lstm
combined
cnns
also
improved
automatic
image
captioning
plethora
applications
===
evaluating
progress
===
ai
like
electricity
steam
engine
general
purpose
technology
consensus
characterize
tasks
ai
tends
excel
projects
alphazero
succeeded
generating
knowledge
scratch
many
machine
learning
projects
require
large
training
datasets
researcher
andrew
ng
suggested
``
highly
imperfect
rule
thumb
''
``
almost
anything
typical
human
less
one
second
mental
thought
probably
near
future
automate
using
ai
''
moravec
's
paradox
suggests
ai
lags
humans
many
tasks
human
brain
specifically
evolved
perform
well
games
provide
well-publicized
benchmark
assessing
rates
progress
alphago
around
2016
brought
era
classical
board-game
benchmarks
close
games
imperfect
knowledge
provide
new
challenges
ai
area
game
theory
e-sports
starcraft
continue
provide
additional
public
benchmarks
many
competitions
prizes
imagenet
challenge
promote
research
artificial
intelligence
common
areas
competition
include
general
machine
intelligence
conversational
behavior
data-mining
robotic
cars
robot
soccer
well
conventional
games
``
imitation
game
''
interpretation
1950
turing
test
assesses
whether
computer
imitate
human
nowadays
considered
exploitable
meaningful
benchmark
derivative
turing
test
completely
automated
public
turing
test
tell
computers
humans
apart
captcha
name
implies
helps
determine
user
actual
person
computer
posing
human
contrast
standard
turing
test
captcha
administered
machine
targeted
human
opposed
administered
human
targeted
machine
computer
asks
user
complete
simple
test
generates
grade
test
computers
unable
solve
problem
correct
solutions
deemed
result
person
taking
test
common
type
captcha
test
requires
typing
distorted
letters
numbers
symbols
appear
image
undecipherable
computer
proposed
``
universal
intelligence
''
tests
aim
compare
well
machines
humans
even
non-human
animals
perform
problem
sets
generic
possible
extreme
test
suite
contain
every
possible
problem
weighted
kolmogorov
complexity
unfortunately
problem
sets
tend
dominated
impoverished
pattern-matching
exercises
tuned
ai
easily
exceed
human
performance
levels
==
applications
==
ai
relevant
intellectual
task
modern
artificial
intelligence
techniques
pervasive
numerous
list
frequently
technique
reaches
mainstream
use
longer
considered
artificial
intelligence
phenomenon
described
ai
effect
high-profile
examples
ai
include
autonomous
vehicles
drones
self-driving
cars
medical
diagnosis
creating
art
poetry
proving
mathematical
theorems
playing
games
chess
go
search
engines
google
search
online
assistants
siri
image
recognition
photographs
spam
filtering
predicting
flight
delays
prediction
judicial
decisions
targeting
online
advertisements
energy
storagewith
social
media
sites
overtaking
tv
source
news
young
people
news
organizations
increasingly
reliant
social
media
platforms
generating
distribution
major
publishers
use
artificial
intelligence
ai
technology
post
stories
effectively
generate
higher
volumes
traffic
ai
also
produce
deepfakes
content-altering
technology
zdnet
reports
``
presents
something
actually
occur
''
though
88
americans
believe
deepfakes
cause
harm
good
47
believe
targeted
boom
election
year
also
opens
public
discourse
threats
videos
falsified
politician
media
===
healthcare
===
ai
healthcare
often
used
classification
whether
automate
initial
evaluation
ct
scan
ekg
identify
high-risk
patients
population
health
breadth
applications
rapidly
increasing
example
ai
applied
high-cost
problem
dosage
issues—where
findings
suggested
ai
could
save
16
billion
2016
groundbreaking
study
california
found
mathematical
formula
developed
help
ai
correctly
determined
accurate
dose
immunosuppressant
drugs
give
organ
patients
artificial
intelligence
assisting
doctors
according
bloomberg
technology
microsoft
developed
ai
help
doctors
find
right
treatments
cancer
great
amount
research
drugs
developed
relating
cancer
detail
800
medicines
vaccines
treat
cancer
negatively
affects
doctors
many
options
choose
making
difficult
choose
right
drugs
patients
microsoft
working
project
develop
machine
called
``
hanover
''
goal
memorize
papers
necessary
cancer
help
predict
combinations
drugs
effective
patient
one
project
worked
moment
fighting
myeloid
leukemia
fatal
cancer
treatment
improved
decades
another
study
reported
found
artificial
intelligence
good
trained
doctors
identifying
skin
cancers
another
study
using
artificial
intelligence
try
monitor
multiple
high-risk
patients
done
asking
patient
numerous
questions
based
data
acquired
live
doctor
patient
interactions
one
study
done
transfer
learning
machine
performed
diagnosis
similarly
well-trained
ophthalmologist
could
generate
decision
within
30
seconds
whether
patient
referred
treatment
95
accuracy
according
cnn
recent
study
surgeons
children
's
national
medical
center
washington
successfully
demonstrated
surgery
autonomous
robot
team
supervised
robot
performed
soft-tissue
surgery
stitching
together
pig
's
bowel
open
surgery
better
human
surgeon
team
claimed
ibm
created
artificial
intelligence
computer
ibm
watson
beaten
human
intelligence
levels
watson
struggled
achieve
success
adoption
healthcare
===
automotive
===
advancements
ai
contributed
growth
automotive
industry
creation
evolution
self-driving
vehicles
2016
30
companies
utilizing
ai
creation
self-driving
cars
companies
involved
ai
include
tesla
google
apple
many
components
contribute
functioning
self-driving
cars
vehicles
incorporate
systems
braking
lane
changing
collision
prevention
navigation
mapping
together
systems
well
high-performance
computers
integrated
one
complex
vehicle
recent
developments
autonomous
automobiles
made
innovation
self-driving
trucks
possible
though
still
testing
phase
uk
government
passed
legislation
begin
testing
self-driving
truck
platoons
2018.
self-driving
truck
platoons
fleet
self-driving
trucks
following
lead
one
non-self-driving
truck
truck
platoons
n't
entirely
autonomous
yet
meanwhile
daimler
german
automobile
corporation
testing
freightliner
inspiration
semi-autonomous
truck
used
highway
one
main
factor
influences
ability
driver-less
automobile
function
mapping
general
vehicle
would
pre-programmed
map
area
driven
map
would
include
data
approximations
street
light
curb
heights
order
vehicle
aware
surroundings
however
google
working
algorithm
purpose
eliminating
need
pre-programmed
maps
instead
creating
device
would
able
adjust
variety
new
surroundings
self-driving
cars
equipped
steering
wheels
brake
pedals
also
research
focused
creating
algorithm
capable
maintaining
safe
environment
passengers
vehicle
awareness
speed
driving
conditions
another
factor
influencing
ability
driver-less
automobile
safety
passenger
make
driver-less
automobile
engineers
must
program
handle
high-risk
situations
situations
could
include
head-on
collision
pedestrians
car
's
main
goal
make
decision
would
avoid
hitting
pedestrians
saving
passengers
car
possibility
car
would
need
make
decision
would
put
someone
danger
words
car
would
need
decide
save
pedestrians
passengers
programming
car
situations
crucial
successful
driver-less
automobile
===
finance
economics
===
financial
institutions
long
used
artificial
neural
network
systems
detect
charges
claims
outside
norm
flagging
human
investigation
use
ai
banking
traced
back
1987
security
pacific
national
bank
us
set-up
fraud
prevention
task
force
counter
unauthorized
use
debit
cards
programs
like
kasisto
moneystream
using
ai
financial
services
banks
use
artificial
intelligence
systems
today
organize
operations
maintain
book-keeping
invest
stocks
manage
properties
ai
react
changes
overnight
business
taking
place
august
2001
robots
beat
humans
simulated
financial
trading
competition
ai
also
reduced
fraud
financial
crimes
monitoring
behavioral
patterns
users
abnormal
changes
anomalies
ai
increasingly
used
corporations
jack
controversially
predicted
ai
ceo
's
30
years
away
use
ai
machines
market
applications
online
trading
decision
making
changed
major
economic
theories
example
ai-based
buying
selling
platforms
changed
law
supply
demand
possible
easily
estimate
individualized
demand
supply
curves
thus
individualized
pricing
furthermore
ai
machines
reduce
information
asymmetry
market
thus
making
markets
efficient
reducing
volume
trades
furthermore
ai
markets
limits
consequences
behavior
markets
making
markets
efficient
theories
ai
impact
include
rational
choice
rational
expectations
game
theory
lewis
turning
point
portfolio
optimization
counterfactual
thinking
..
august
2019
aicpa
introduced
ai
training
course
accounting
professionals
===
cybersecurity
===
cybersecurity
arena
faces
significant
challenges
form
large-scale
hacking
attacks
different
types
harm
organizations
kinds
create
billions
dollars
business
damage
artificial
intelligence
natural
language
processing
nlp
begun
used
security
companies
example
siem
security
information
event
management
solutions
advanced
solutions
use
ai
nlp
automatically
sort
data
networks
high
risk
low-risk
information
enables
security
teams
focus
attacks
potential
real
harm
organization
become
victims
attacks
denial
service
dos
malware
others
===
government
===
artificial
intelligence
government
consists
applications
regulation
artificial
intelligence
paired
facial
recognition
systems
may
used
mass
surveillance
already
case
parts
china
artificial
intelligence
also
competed
tama
city
mayoral
elections
2018.
2019
tech
city
bengaluru
india
set
deploy
ai
managed
traffic
signal
systems
across
387
traffic
signals
city
system
involve
use
cameras
ascertain
traffic
density
accordingly
calculate
time
needed
clear
traffic
volume
determine
signal
duration
vehicular
traffic
across
streets
===
law-related
professions
===
artificial
intelligence
ai
becoming
mainstay
component
law-related
professions
circumstances
analytics-crunching
technology
using
algorithms
machine
learning
work
previously
done
entry-level
lawyers
electronic
discovery
ediscovery
industry
focused
machine
learning
predictive
coding/technology
assisted
review
subset
ai
add
soup
applications
natural
language
processing
nlp
automated
speech
recognition
asr
also
vogue
industry
===
video
games
===
video
games
artificial
intelligence
routinely
used
generate
dynamic
purposeful
behavior
non-player
characters
npcs
addition
well-understood
ai
techniques
routinely
used
pathfinding
researchers
consider
npc
ai
games
``
solved
problem
''
production
tasks
games
atypical
ai
include
ai
director
left
4
dead
2008
neuroevolutionary
training
platoons
supreme
commander
2
2010
===
military
===
main
military
applications
artificial
intelligence
machine
learning
enhance
c2
communications
sensors
integration
interoperability
artificial
intelligence
technologies
enable
coordination
sensors
effectors
threat
detection
identification
marking
enemy
positions
target
acquisition
coordination
deconfliction
distributed
join
fires
networked
combat
vehicles
tanks
also
inside
manned
unmanned
teams
mum-t
.worldwide
annual
military
spending
robotics
rose
us
5.1
billion
2010
us
7.5
billion
2015.
military
drones
capable
autonomous
action
widely
considered
useful
asset
many
artificial
intelligence
researchers
seek
distance
military
applications
ai
===
hospitality
===
hospitality
industry
artificial
intelligence
based
solutions
used
reduce
staff
load
increase
efficiency
cutting
repetitive
tasks
frequency
trends
analysis
guest
interaction
customer
needs
prediction
hotel
services
backed
artificial
intelligence
represented
form
chatbot
application
virtual
voice
assistant
service
robots
===
audit
===
financial
statements
audit
ai
makes
continuous
audit
possible
ai
tools
could
analyze
many
sets
different
information
immediately
potential
benefit
would
overall
audit
risk
reduced
level
assurance
increased
time
duration
audit
reduced
===
advertising
===
possible
use
ai
predict
generalize
behavior
customers
digital
footprints
order
target
personalized
promotions
build
customer
personas
automatically
documented
case
reports
online
gambling
companies
using
ai
improve
customer
targeting
moreover
application
personality
computing
ai
models
help
reducing
cost
advertising
campaigns
adding
psychological
targeting
traditional
sociodemographic
behavioral
targeting
===
art
===
artificial
intelligence
inspired
numerous
creative
applications
including
usage
produce
visual
art
exhibition
``
thinking
machines
art
design
computer
age
1959–1989
''
moma
provides
good
overview
historical
applications
ai
art
architecture
design
recent
exhibitions
showcasing
usage
ai
produce
art
include
google-sponsored
benefit
auction
gray
area
foundation
san
francisco
artists
experimented
deepdream
algorithm
exhibition
``
unhuman
art
age
ai
''
took
place
los
angeles
frankfurt
fall
2017.
spring
2018
association
computing
machinery
dedicated
special
magazine
issue
subject
computers
art
highlighting
role
machine
learning
arts
austrian
ars
electronica
museum
applied
arts
vienna
opened
exhibitions
ai
2019.
ars
electronica
's
2019
festival
``
box
''
extensively
thematized
role
arts
sustainable
societal
transformation
ai
==
philosophy
ethics
==
three
philosophical
questions
related
ai
artificial
general
intelligence
possible
machine
solve
problem
human
solve
using
intelligence
hard
limits
machine
accomplish
intelligent
machines
dangerous
ensure
machines
behave
ethically
used
ethically
machine
mind
consciousness
mental
states
exactly
sense
human
beings
machine
sentient
thus
deserve
certain
rights
machine
intentionally
cause
harm
===
limits
artificial
general
intelligence
===
machine
intelligent
``
think
''
alan
turing
's
``
polite
convention
''
need
decide
machine
``
think
''
need
decide
machine
act
intelligently
human
approach
philosophical
problems
associated
artificial
intelligence
forms
basis
turing
test
dartmouth
proposal
''
every
aspect
learning
feature
intelligence
precisely
described
machine
made
simulate
''
conjecture
printed
proposal
dartmouth
conference
1956.newell
simon
's
physical
symbol
system
hypothesis
''
physical
symbol
system
necessary
sufficient
means
general
intelligent
action
''
newell
simon
argue
intelligence
consists
formal
operations
symbols
hubert
dreyfus
argued
contrary
human
expertise
depends
unconscious
instinct
rather
conscious
symbol
manipulation
``
feel
''
situation
rather
explicit
symbolic
knowledge
see
dreyfus
critique
ai
gödelian
arguments
gödel
john
lucas
1961
roger
penrose
detailed
argument
1989
onwards
made
highly
technical
arguments
human
mathematicians
consistently
see
truth
``
gödel
statements
''
therefore
computational
abilities
beyond
mechanical
turing
machines
however
people
agree
``
gödelian
arguments
''
.the
artificial
brain
argument
brain
simulated
machines
brains
intelligent
simulated
brains
must
also
intelligent
thus
machines
intelligent
hans
moravec
ray
kurzweil
others
argued
technologically
feasible
copy
brain
directly
hardware
software
simulation
essentially
identical
original
ai
effect
machines
already
intelligent
observers
failed
recognize
deep
blue
beat
garry
kasparov
chess
machine
acting
intelligently
however
onlookers
commonly
discount
behavior
artificial
intelligence
program
arguing
``
real
''
intelligence
thus
``
real
''
intelligence
whatever
intelligent
behavior
people
machines
still
known
ai
effect
``
ai
whatever
n't
done
yet
''
===
potential
harm
===
widespread
use
artificial
intelligence
could
unintended
consequences
dangerous
undesirable
scientists
future
life
institute
among
others
described
short-term
research
goals
see
ai
influences
economy
laws
ethics
involved
ai
minimize
ai
security
risks
long-term
scientists
proposed
continue
optimizing
function
minimizing
possible
security
risks
come
along
new
technologies
potential
negative
effects
ai
automation
major
issue
andrew
yang
's
2020
presidential
campaign
united
states
irakli
beridze
head
centre
artificial
intelligence
robotics
unicri
united
nations
expressed
``
think
dangerous
applications
ai
point
view
would
criminals
large
terrorist
organizations
using
disrupt
large
processes
simply
pure
harm
terrorists
could
cause
harm
via
digital
warfare
could
combination
robotics
drones
ai
things
well
could
really
dangerous
course
risks
come
things
like
job
losses
massive
numbers
people
losing
jobs
n't
find
solution
extremely
dangerous
things
like
lethal
autonomous
weapons
systems
properly
governed
—
otherwise
's
massive
potential
misuse
''
====
existential
risk
====
physicist
stephen
hawking
microsoft
founder
bill
gates
spacex
founder
elon
musk
expressed
concerns
possibility
ai
could
evolve
point
humans
could
control
hawking
theorizing
could
``
spell
end
human
race
''
development
full
artificial
intelligence
could
spell
end
human
race
humans
develop
artificial
intelligence
take
redesign
ever-increasing
rate
humans
limited
slow
biological
evolution
could
n't
compete
would
superseded
book
superintelligence
philosopher
nick
bostrom
provides
argument
artificial
intelligence
pose
threat
humankind
argues
sufficiently
intelligent
ai
chooses
actions
based
achieving
goal
exhibit
convergent
behavior
acquiring
resources
protecting
shut
ai
's
goals
fully
reflect
humanity's—one
example
ai
told
compute
many
digits
pi
possible—it
might
harm
humanity
order
acquire
resources
prevent
shut
ultimately
better
achieve
goal
bostrom
also
emphasizes
difficulty
fully
conveying
humanity
's
values
advanced
ai
uses
hypothetical
example
giving
ai
goal
make
humans
smile
illustrate
misguided
attempt
ai
scenario
become
superintelligent
bostrom
argues
may
resort
methods
humans
would
find
horrifying
inserting
``
electrodes
facial
muscles
humans
cause
constant
beaming
grins
''
would
efficient
way
achieve
goal
making
humans
smile
book
human
compatible
ai
researcher
stuart
j.
russell
echoes
bostrom
's
concerns
also
proposing
approach
developing
provably
beneficial
machines
focused
uncertainty
deference
humans
possibly
involving
inverse
reinforcement
learning
concern
risk
artificial
intelligence
led
high-profile
donations
investments
group
prominent
tech
titans
including
peter
thiel
amazon
web
services
musk
committed
1
billion
openai
nonprofit
company
aimed
championing
responsible
ai
development
opinion
experts
within
field
artificial
intelligence
mixed
sizable
fractions
concerned
unconcerned
risk
eventual
superhumanly-capable
ai
technology
industry
leaders
believe
artificial
intelligence
helpful
current
form
continue
assist
humans
oracle
ceo
mark
hurd
stated
ai
``
actually
create
jobs
less
jobs
''
humans
needed
manage
ai
systems
facebook
ceo
mark
zuckerberg
believes
ai
``
unlock
huge
amount
positive
things
''
curing
disease
increasing
safety
autonomous
cars
january
2015
musk
donated
10
million
future
life
institute
fund
research
understanding
ai
decision
making
goal
institute
``
grow
wisdom
manage
''
growing
power
technology
musk
also
funds
companies
developing
artificial
intelligence
deepmind
vicarious
``
keep
eye
's
going
artificial
intelligence
think
potentially
dangerous
outcome
``
danger
uncontrolled
advanced
ai
realized
hypothetical
ai
would
overpower
out-think
humanity
minority
experts
argue
possibility
far
enough
future
worth
researching
counterarguments
revolve
around
humans
either
intrinsically
convergently
valuable
perspective
artificial
intelligence
====
devaluation
humanity
====
joseph
weizenbaum
wrote
ai
applications
definition
successfully
simulate
genuine
human
empathy
use
ai
technology
fields
customer
service
psychotherapy
deeply
misguided
weizenbaum
also
bothered
ai
researchers
philosophers
willing
view
human
mind
nothing
computer
program
position
known
computationalism
weizenbaum
points
suggest
ai
research
devalues
human
life
====
social
justice
====
one
concern
ai
programs
may
programmed
biased
certain
groups
women
minorities
developers
wealthy
caucasian
men
support
artificial
intelligence
higher
among
men
47
approving
women
35
approving
algorithms
host
applications
today
's
legal
system
already
assisting
officials
ranging
judges
parole
officers
public
defenders
gauging
predicted
likelihood
recidivism
defendants
compas
acronym
correctional
offender
management
profiling
alternative
sanctions
counts
among
widely
utilized
commercially
available
solutions
suggested
compas
assigns
exceptionally
elevated
risk
recidivism
black
defendants
conversely
ascribing
low
risk
estimate
white
defendants
significantly
often
statistically
expected
====
decrease
demand
human
labor
====
relationship
automation
employment
complicated
automation
eliminates
old
jobs
also
creates
new
jobs
micro-economic
macro-economic
effects
unlike
previous
waves
automation
many
middle-class
jobs
may
eliminated
artificial
intelligence
economist
states
``
worry
ai
could
white-collar
jobs
steam
power
blue-collar
ones
industrial
revolution
''
``
worth
taking
seriously
''
subjective
estimates
risk
vary
widely
example
michael
osborne
carl
benedikt
frey
estimate
47
u.s.
jobs
``
high
risk
''
potential
automation
oecd
report
classifies
9
u.s.
jobs
``
high
risk
''
jobs
extreme
risk
range
paralegals
fast
food
cooks
job
demand
likely
increase
care-related
professions
ranging
personal
healthcare
clergy
author
martin
ford
others
go
argue
many
jobs
routine
repetitive
ai
predictable
ford
warns
jobs
may
automated
next
couple
decades
many
new
jobs
may
``
accessible
people
average
capability
''
even
retraining
economists
point
past
technology
tended
increase
rather
reduce
total
employment
acknowledge
``
're
uncharted
territory
''
ai
====
autonomous
weapons
====
currently
50+
countries
researching
battlefield
robots
including
united
states
china
russia
united
kingdom
many
people
concerned
risk
superintelligent
ai
also
want
limit
use
artificial
soldiers
drones
===
ethical
machines
===
machines
intelligence
potential
use
intelligence
prevent
harm
minimize
risks
may
ability
use
ethical
reasoning
better
choose
actions
world
need
policy
making
devise
policies
regulate
artificial
intelligence
robotics
research
area
includes
machine
ethics
artificial
moral
agents
friendly
ai
discussion
towards
building
human
rights
framework
also
talks
====
artificial
moral
agents
====
wendell
wallach
introduced
concept
artificial
moral
agents
ama
book
moral
machines
wallach
amas
become
part
research
landscape
artificial
intelligence
guided
two
central
questions
identifies
``
humanity
want
computers
making
moral
decisions
''
``
ro
bots
really
moral
''
wallach
question
centered
issue
whether
machines
demonstrate
equivalent
moral
behavior
contrast
constraints
society
may
place
development
amas
====
machine
ethics
====
field
machine
ethics
concerned
giving
machines
ethical
principles
procedure
discovering
way
resolve
ethical
dilemmas
might
encounter
enabling
function
ethically
responsible
manner
ethical
decision
making
field
delineated
aaai
fall
2005
symposium
machine
ethics
``
past
research
concerning
relationship
technology
ethics
largely
focused
responsible
irresponsible
use
technology
human
beings
people
interested
human
beings
ought
treat
machines
cases
human
beings
engaged
ethical
reasoning
time
come
adding
ethical
dimension
least
machines
recognition
ethical
ramifications
behavior
involving
machines
well
recent
potential
developments
machine
autonomy
necessitate
contrast
computer
hacking
software
property
issues
privacy
issues
topics
normally
ascribed
computer
ethics
machine
ethics
concerned
behavior
machines
towards
human
users
machines
research
machine
ethics
key
alleviating
concerns
autonomous
systems—it
could
argued
notion
autonomous
machines
without
dimension
root
fear
concerning
machine
intelligence
investigation
machine
ethics
could
enable
discovery
problems
current
ethical
theories
advancing
thinking
ethics
''
machine
ethics
sometimes
referred
machine
morality
computational
ethics
computational
morality
variety
perspectives
nascent
field
found
collected
edition
``
machine
ethics
''
stems
aaai
fall
2005
symposium
machine
ethics
====
malevolent
friendly
ai
====
political
scientist
charles
t.
rubin
believes
ai
neither
designed
guaranteed
benevolent
argues
``
sufficiently
advanced
benevolence
may
indistinguishable
malevolence
''
humans
assume
machines
robots
would
treat
us
favorably
priori
reason
believe
would
sympathetic
system
morality
evolved
along
particular
biology
ais
would
share
hyper-intelligent
software
may
necessarily
decide
support
continued
existence
humanity
would
extremely
difficult
stop
topic
also
recently
begun
discussed
academic
publications
real
source
risks
civilization
humans
planet
earth
one
proposal
deal
ensure
first
generally
intelligent
ai
'friendly
ai
able
control
subsequently
developed
ais
question
whether
kind
check
could
actually
remain
place
leading
ai
researcher
rodney
brooks
writes
``
think
mistake
worrying
us
developing
malevolent
ai
anytime
next
hundred
years
think
worry
stems
fundamental
error
distinguishing
difference
real
recent
advances
particular
aspect
ai
enormity
complexity
building
sentient
volitional
intelligence
''
===
machine
consciousness
sentience
mind
===
ai
system
replicates
key
aspects
human
intelligence
system
also
sentient—will
mind
conscious
experiences
question
closely
related
philosophical
problem
nature
human
consciousness
generally
referred
hard
problem
consciousness
====
consciousness
====
david
chalmers
identified
two
problems
understanding
mind
named
``
hard
''
``
easy
''
problems
consciousness
easy
problem
understanding
brain
processes
signals
makes
plans
controls
behavior
hard
problem
explaining
feels
feel
like
anything
human
information
processing
easy
explain
however
human
subjective
experience
difficult
explain
example
consider
happens
person
shown
color
swatch
identifies
saying
``
's
red
''
easy
problem
requires
understanding
machinery
brain
makes
possible
person
know
color
swatch
red
hard
problem
people
also
know
something
else—they
also
know
red
looks
like
consider
person
born
blind
know
something
red
without
knowing
red
looks
like
everyone
knows
subjective
experience
exists
every
day
e.g.
sighted
people
know
red
looks
like
hard
problem
explaining
brain
creates
exists
different
knowledge
aspects
brain
====
computationalism
functionalism
====
computationalism
position
philosophy
mind
human
mind
human
brain
information
processing
system
thinking
form
computing
computationalism
argues
relationship
mind
body
similar
identical
relationship
software
hardware
thus
may
solution
mind-body
problem
philosophical
position
inspired
work
ai
researchers
cognitive
scientists
1960s
originally
proposed
philosophers
jerry
fodor
hilary
putnam
====
strong
ai
hypothesis
====
philosophical
position
john
searle
named
``
strong
ai
''
states
``
appropriately
programmed
computer
right
inputs
outputs
would
thereby
mind
exactly
sense
human
beings
minds
''
searle
counters
assertion
chinese
room
argument
asks
us
look
inside
computer
try
find
``
mind
''
might
====
robot
rights
====
machine
created
intelligence
could
also
feel
feel
rights
human
issue
known
``
robot
rights
''
currently
considered
example
california
's
institute
future
although
many
critics
believe
discussion
premature
critics
transhumanism
argue
hypothetical
robot
rights
would
lie
spectrum
animal
rights
human
rights
subject
profoundly
discussed
2010
documentary
film
plug
pray
many
sci
fi
media
star
trek
next
generation
character
commander
data
fought
disassembled
research
wanted
``
become
human
''
robotic
holograms
voyager
===
superintelligence
===
limits
intelligent
machines—or
human-machine
hybrids—can
superintelligence
hyperintelligence
superhuman
intelligence
hypothetical
agent
would
possess
intelligence
far
surpassing
brightest
gifted
human
mind
superintelligence
may
also
refer
form
degree
intelligence
possessed
agent
====
technological
singularity
====
research
strong
ai
produced
sufficiently
intelligent
software
might
able
reprogram
improve
improved
software
would
even
better
improving
leading
recursive
self-improvement
new
intelligence
could
thus
increase
exponentially
dramatically
surpass
humans
science
fiction
writer
vernor
vinge
named
scenario
``
singularity
''
technological
singularity
accelerating
progress
technologies
cause
runaway
effect
wherein
artificial
intelligence
exceed
human
intellectual
capacity
control
thus
radically
changing
even
ending
civilization
capabilities
intelligence
may
impossible
comprehend
technological
singularity
occurrence
beyond
events
unpredictable
even
unfathomable
ray
kurzweil
used
moore
's
law
describes
relentless
exponential
improvement
digital
technology
calculate
desktop
computers
processing
power
human
brains
year
2029
predicts
singularity
occur
2045
====
transhumanism
====
robot
designer
hans
moravec
cyberneticist
kevin
warwick
inventor
ray
kurzweil
predicted
humans
machines
merge
future
cyborgs
capable
powerful
either
idea
called
transhumanism
roots
aldous
huxley
robert
ettinger
edward
fredkin
argues
``
artificial
intelligence
next
stage
evolution
''
idea
first
proposed
samuel
butler
's
``
darwin
among
machines
''
far
back
1863
expanded
upon
george
dyson
book
name
1998
==
economics
==
long-term
economic
effects
ai
uncertain
survey
economists
showed
disagreement
whether
increasing
use
robots
ai
cause
substantial
increase
long-term
unemployment
generally
agree
could
net
benefit
productivity
gains
redistributed
february
2020
european
union
white
paper
artificial
intelligence
advocated
artificial
intelligence
economic
benefits
including
``
improving
healthcare
e.g
making
diagnosis
precise
enabling
better
prevention
diseases
increasing
efficiency
farming
contributing
climate
change
mitigation
adaptation
improving
efficiency
production
systems
predictive
maintenance
''
acknowledging
potential
risks
==
regulation
==
development
public
sector
policies
promoting
regulating
artificial
intelligence
ai
considered
necessary
encourage
ai
manage
associated
risks
challenging
2017
elon
musk
called
regulation
ai
development
february
2020
european
union
published
draft
strategy
paper
promoting
regulating
ai
==
fiction
==
thought-capable
artificial
beings
appeared
storytelling
devices
since
antiquity
persistent
theme
science
fiction
common
trope
works
began
mary
shelley
's
frankenstein
human
creation
becomes
threat
masters
includes
works
arthur
c.
clarke
's
stanley
kubrick
's
2001
space
odyssey
1968
hal
9000
murderous
computer
charge
discovery
one
spaceship
well
terminator
1984
matrix
1999
contrast
rare
loyal
robots
gort
day
earth
stood
still
1951
bishop
aliens
1986
less
prominent
popular
culture
isaac
asimov
introduced
three
laws
robotics
many
books
stories
notably
``
multivac
''
series
super-intelligent
computer
name
asimov
's
laws
often
brought
lay
discussions
machine
ethics
almost
artificial
intelligence
researchers
familiar
asimov
's
laws
popular
culture
generally
consider
laws
useless
many
reasons
one
ambiguity
transhumanism
merging
humans
machines
explored
manga
ghost
shell
science-fiction
series
dune
1980s
artist
hajime
sorayama
's
sexy
robots
series
painted
published
japan
depicting
actual
organic
human
form
lifelike
muscular
metallic
skins
later
``
gynoids
''
book
followed
used
influenced
movie
makers
including
george
lucas
creatives
sorayama
never
considered
organic
robots
real
part
nature
always
unnatural
product
human
mind
fantasy
existing
mind
even
realized
actual
form
several
works
use
ai
force
us
confront
fundamental
question
makes
us
human
showing
us
artificial
beings
ability
feel
thus
suffer
appears
karel
čapek
's
r.u.r.
films
a.i
artificial
intelligence
ex
machina
well
novel
androids
dream
electric
sheep
philip
k.
dick
dick
considers
idea
understanding
human
subjectivity
altered
technology
created
artificial
intelligence
==
see
also
==
==
explanatory
notes
==
==
references
==
===
ai
textbooks
===
===
history
ai
===
===
sources
===
==
reading
==
==
external
links
==
''
artificial
intelligence
''
internet
encyclopedia
philosophy
thomason
richmond
``
logic
artificial
intelligence
''
zalta
edward
n
ed.
stanford
encyclopedia
philosophy
aitopics
–
large
directory
links
resources
maintained
association
advancement
artificial
intelligence
leading
organization
academic
ai
researchers
artificial
intelligence
bbc
radio
4
discussion
john
agar
alison
adam
igor
aleksander
time
dec.
8
2005
https
//en.wikipedia.org/wiki/neural_network
artificial
neural
networks
ann
connectionist
systems
computing
systems
vaguely
inspired
biological
neural
networks
constitute
animal
brains
systems
``
learn
''
perform
tasks
considering
examples
generally
without
programmed
task-specific
rules
example
image
recognition
might
learn
identify
images
contain
cats
analyzing
example
images
manually
labeled
``
cat
''
``
cat
''
using
results
identify
cats
images
without
prior
knowledge
cats
example
fur
tails
whiskers
cat-like
faces
instead
automatically
generate
identifying
characteristics
examples
process
ann
based
collection
connected
units
nodes
called
artificial
neurons
loosely
model
neurons
biological
brain
connection
like
synapses
biological
brain
transmit
signal
neurons
artificial
neuron
receives
signal
processes
signal
neurons
connected
ann
implementations
``
signal
''
connection
real
number
output
neuron
computed
non-linear
function
sum
inputs
connections
called
edges
neurons
edges
typically
weight
adjusts
learning
proceeds
weight
increases
decreases
strength
signal
connection
neurons
may
threshold
signal
sent
aggregate
signal
crosses
threshold
typically
neurons
aggregated
layers
different
layers
may
perform
different
transformations
inputs
signals
travel
first
layer
input
layer
last
layer
output
layer
possibly
traversing
layers
multiple
times
original
goal
ann
approach
solve
problems
way
human
brain
would
time
attention
moved
performing
specific
tasks
leading
deviations
biology
anns
used
variety
tasks
including
computer
vision
speech
recognition
machine
translation
social
network
filtering
playing
board
video
games
medical
diagnosis
even
activities
traditionally
considered
reserved
humans
like
painting
==
history
==
warren
mcculloch
walter
pitts
1943
opened
subject
creating
computational
model
neural
networks
late
1940s
d.
o.
hebb
created
learning
hypothesis
based
mechanism
neural
plasticity
became
known
hebbian
learning
farley
wesley
a.
clark
1954
first
used
computational
machines
called
``
calculators
''
simulate
hebbian
network
rosenblatt
1958
created
perceptron
first
functional
networks
many
layers
published
ivakhnenko
lapa
1965
group
method
data
handling
basics
continuous
backpropagation
derived
context
control
theory
kelley
1960
bryson
1961
using
principles
dynamic
programming
1970
seppo
linnainmaa
published
general
method
automatic
differentiation
ad
discrete
connected
networks
nested
differentiable
functions
1973
dreyfus
used
backpropagation
adapt
parameters
controllers
proportion
error
gradients
werbos
's
1975
backpropagation
algorithm
enabled
practical
training
multi-layer
networks
1982
applied
linnainmaa
's
ad
method
neural
networks
way
became
widely
used
thereafter
research
stagnated
following
minsky
papert
1969
discovered
basic
perceptrons
incapable
processing
exclusive-or
circuit
computers
lacked
sufficient
power
process
useful
neural
networks
1992
max-pooling
introduced
help
least-shift
invariance
tolerance
deformation
aid
3d
object
recognition
schmidhuber
adopted
multi-level
hierarchy
networks
1992
pre-trained
one
level
time
unsupervised
learning
fine-tuned
backpropagation
development
metal–oxide–semiconductor
mos
very-large-scale
integration
vlsi
form
complementary
mos
cmos
technology
enabled
development
practical
artificial
neural
networks
1980s
landmark
publication
field
1989
book
analog
vlsi
implementation
neural
systems
carver
a.
mead
mohammed
ismail
geoffrey
hinton
et
al
2006
proposed
learning
high-level
representation
using
successive
layers
binary
real-valued
latent
variables
restricted
boltzmann
machine
model
layer
2012
ng
dean
created
network
learned
recognize
higher-level
concepts
cats
watching
unlabeled
images
unsupervised
pre-training
increased
computing
power
gpus
distributed
computing
allowed
use
larger
networks
particularly
image
visual
recognition
problems
became
known
``
deep
learning
''
ciresan
colleagues
2010
showed
despite
vanishing
gradient
problem
gpus
make
backpropagation
feasible
many-layered
feedforward
neural
networks
2009
2012
anns
began
winning
prizes
ann
contests
approaching
human
level
performance
various
tasks
initially
pattern
recognition
machine
learning
example
bi-directional
multi-dimensional
long
short-term
memory
lstm
graves
et
al
three
competitions
connected
handwriting
recognition
2009
without
prior
knowledge
three
languages
learned
ciresan
colleagues
built
first
pattern
recognizers
achieve
human-competitive/superhuman
performance
benchmarks
traffic
sign
recognition
ijcnn
2012
==
models
==
anns
began
attempt
exploit
architecture
human
brain
perform
tasks
conventional
algorithms
little
success
soon
reoriented
towards
improving
empirical
results
mostly
abandoning
attempts
remain
true
biological
precursors
neurons
connected
various
patterns
allow
output
neurons
become
input
others
network
forms
directed
weighted
graph
artificial
neural
network
consists
collection
simulated
neurons
neuron
node
connected
nodes
via
links
correspond
biological
axon-synapse-dendrite
connections
link
weight
determines
strength
one
node
's
influence
another
===
components
anns
===
====
neurons
====
anns
composed
artificial
neurons
retain
biological
concept
neurons
receive
input
combine
input
internal
state
activation
optional
threshold
using
activation
function
produce
output
using
output
function
initial
inputs
external
data
images
documents
ultimate
outputs
accomplish
task
recognizing
object
image
important
characteristic
activation
function
provides
smooth
differentiable
transition
input
values
change
i.e
small
change
input
produces
small
change
output
====
connections
weights
====
network
consists
connections
connection
providing
output
one
neuron
input
another
neuron
connection
assigned
weight
represents
relative
importance
given
neuron
multiple
input
output
connections
====
propagation
function
====
propagation
function
computes
input
neuron
outputs
predecessor
neurons
connections
weighted
sum
bias
term
added
result
propagation
===
organization
===
neurons
typically
organized
multiple
layers
especially
deep
learning
neurons
one
layer
connect
neurons
immediately
preceding
immediately
following
layers
layer
receives
external
data
input
layer
layer
produces
ultimate
result
output
layer
zero
hidden
layers
single
layer
unlayered
networks
also
used
two
layers
multiple
connection
patterns
possible
fully
connected
every
neuron
one
layer
connecting
every
neuron
next
layer
pooling
group
neurons
one
layer
connect
single
neuron
next
layer
thereby
reducing
number
neurons
layer
neurons
connections
form
directed
acyclic
graph
known
feedforward
networks
alternatively
networks
allow
connections
neurons
previous
layers
known
recurrent
networks
===
hyperparameter
===
hyperparameter
constant
parameter
whose
value
set
learning
process
begins
values
parameters
derived
via
learning
examples
hyperparameters
include
learning
rate
number
hidden
layers
batch
size
values
hyperparameters
dependent
hyperparameters
example
size
layers
depend
overall
number
layers
===
learning
===
learning
adaptation
network
better
handle
task
considering
sample
observations
learning
involves
adjusting
weights
optional
thresholds
network
improve
accuracy
result
done
minimizing
observed
errors
learning
complete
examining
additional
observations
usefully
reduce
error
rate
even
learning
error
rate
typically
reach
0.
learning
error
rate
high
network
typically
must
redesigned
practically
done
defining
cost
function
evaluated
periodically
learning
long
output
continues
decline
learning
continues
cost
frequently
defined
statistic
whose
value
approximated
outputs
actually
numbers
error
low
difference
output
almost
certainly
cat
correct
answer
cat
small
learning
attempts
reduce
total
differences
across
observations
learning
models
viewed
straightforward
application
optimization
theory
statistical
estimation
====
learning
rate
====
learning
rate
defines
size
corrective
steps
model
takes
adjust
errors
observation
high
learning
rate
shortens
training
time
lower
ultimate
accuracy
lower
learning
rate
takes
longer
potential
greater
accuracy
optimizations
quickprop
primarily
aimed
speeding
error
minimization
improvements
mainly
try
increase
reliability
order
avoid
oscillation
inside
network
alternating
connection
weights
improve
rate
convergence
refinements
use
adaptive
learning
rate
increases
decreases
appropriate
concept
momentum
allows
balance
gradient
previous
change
weighted
weight
adjustment
depends
degree
previous
change
momentum
close
0
emphasizes
gradient
value
close
1
emphasizes
last
change
====
cost
function
====
possible
define
cost
function
ad
hoc
frequently
choice
determined
functions
desirable
properties
convexity
arises
model
e.g.
probabilistic
model
model
's
posterior
probability
used
inverse
cost
====
backpropagation
====
backpropagation
method
adjust
connection
weights
compensate
error
found
learning
error
amount
effectively
divided
among
connections
technically
backprop
calculates
gradient
derivative
cost
function
associated
given
state
respect
weights
weight
updates
done
via
stochastic
gradient
descent
methods
extreme
learning
machines
``
no-prop
''
networks
training
without
backtracking
``
weightless
''
networks
non-connectionist
neural
networks
===
learning
paradigms
===
three
major
learning
paradigms
supervised
learning
unsupervised
learning
reinforcement
learning
correspond
particular
learning
task
====
supervised
learning
====
supervised
learning
uses
set
paired
inputs
desired
outputs
learning
task
produce
desired
output
input
case
cost
function
related
eliminating
incorrect
deductions
commonly
used
cost
mean-squared
error
tries
minimize
average
squared
error
network
's
output
desired
output
tasks
suited
supervised
learning
pattern
recognition
also
known
classification
regression
also
known
function
approximation
supervised
learning
also
applicable
sequential
data
e.g.
hand
writing
speech
gesture
recognition
thought
learning
``
teacher
''
form
function
provides
continuous
feedback
quality
solutions
obtained
thus
far
====
unsupervised
learning
====
unsupervised
learning
input
data
given
along
cost
function
function
data
x
\displaystyle
\textstyle
x
network
's
output
cost
function
dependent
task
model
domain
priori
assumptions
implicit
properties
model
parameters
observed
variables
trivial
example
consider
model
f
x
\displaystyle
\textstyle
f
x
=a
\displaystyle
\textstyle
constant
cost
c
e
x
−
f
x
2
\displaystyle
\textstyle
c=e
x-f
x
2
minimizing
cost
produces
value
\displaystyle
\textstyle
equal
mean
data
cost
function
much
complicated
form
depends
application
example
compression
could
related
mutual
information
x
\displaystyle
\textstyle
x
f
x
\displaystyle
\textstyle
f
x
whereas
statistical
modeling
could
related
posterior
probability
model
given
data
note
examples
quantities
would
maximized
rather
minimized
tasks
fall
within
paradigm
unsupervised
learning
general
estimation
problems
applications
include
clustering
estimation
statistical
distributions
compression
filtering
====
reinforcement
learning
====
applications
playing
video
games
actor
takes
string
actions
receiving
generally
unpredictable
response
environment
one
goal
win
game
i.e.
generate
positive
lowest
cost
responses
reinforcement
learning
aim
weight
network
devise
policy
perform
actions
minimize
long-term
expected
cumulative
cost
point
time
agent
performs
action
environment
generates
observation
instantaneous
cost
according
usually
unknown
rules
rules
long-term
cost
usually
estimated
juncture
agent
decides
whether
explore
new
actions
uncover
costs
exploit
prior
learning
proceed
quickly
formally
environment
modeled
markov
decision
process
mdp
states
1
n
∈
\displaystyle
\textstyle
s_
1
...
s_
n
\in
actions
1
∈
\displaystyle
\textstyle
a_
1
...
a_
\in
state
transitions
known
probability
distributions
used
instead
instantaneous
cost
distribution
p
c
\displaystyle
\textstyle
p
c_
|s_
observation
distribution
p
x
\displaystyle
\textstyle
p
x_
|s_
transition
distribution
p
1
\displaystyle
\textstyle
p
s_
t+1
|s_
a_
policy
defined
conditional
distribution
actions
given
observations
taken
together
two
define
markov
chain
mc
aim
discover
lowest-cost
mc
anns
serve
learning
component
applications
dynamic
programming
coupled
anns
giving
neurodynamic
programming
applied
problems
involved
vehicle
routing
video
games
natural
resource
management
medicine
anns
ability
mitigate
losses
accuracy
even
reducing
discretization
grid
density
numerically
approximating
solution
control
problems
tasks
fall
within
paradigm
reinforcement
learning
control
problems
games
sequential
decision
making
tasks
====
self
learning
====
self
learning
neural
networks
introduced
1982
along
neural
network
capable
self-learning
named
crossbar
adaptive
array
caa
system
one
input
situation
one
output
action
behavior
a.
neither
external
advice
input
external
reinforcement
input
environment
caa
computes
crossbar
fashion
decisions
actions
emotions
feelings
encountered
situations
system
driven
interaction
cognition
emotion
given
memory
matrix
w
=||w
||
crossbar
self
learning
algorithm
iteration
performs
following
computation
situation
perform
action
receive
consequence
situation
’
compute
emotion
consequence
situation
v
’
update
crossbar
memory
w
’
w
v
’
backpropagated
value
secondary
reinforcement
emotion
toward
consequence
situation
caa
exists
two
environments
one
behavioral
environment
behaves
genetic
environment
initially
receives
initial
emotions
encountered
situations
behavioral
environment
received
genome
vector
species
vector
genetic
environment
caa
learn
goal-seeking
behavior
behavioral
environment
contains
desirable
undesirable
situations
===
===
bayesian
framework
distribution
set
allowed
models
chosen
minimize
cost
evolutionary
methods
gene
expression
programming
simulated
annealing
expectation-maximization
non-parametric
methods
particle
swarm
optimization
learning
algorithms
convergent
recursion
learning
algorithm
cerebellar
model
articulation
controller
cmac
neural
networks
====
modes
====
two
modes
learning
available
stochastic
batch
stochastic
learning
input
creates
weight
adjustment
batch
learning
weights
adjusted
based
batch
inputs
accumulating
errors
batch
stochastic
learning
introduces
``
noise
''
process
using
local
gradient
calculated
one
data
point
reduces
chance
network
getting
stuck
local
minima
however
batch
learning
typically
yields
faster
stable
descent
local
minimum
since
update
performed
direction
batch
's
average
error
common
compromise
use
``
mini-batches
''
small
batches
samples
batch
selected
stochastically
entire
data
set
==
types
==
anns
evolved
broad
family
techniques
advanced
state
art
across
multiple
domains
simplest
types
one
static
components
including
number
units
number
layers
unit
weights
topology
dynamic
types
allow
one
evolve
via
learning
latter
much
complicated
shorten
learning
periods
produce
better
results
types
allow/require
learning
``
supervised
''
operator
others
operate
independently
types
operate
purely
hardware
others
purely
software
run
general
purpose
computers
main
breakthroughs
include
convolutional
neural
networks
proven
particularly
successful
processing
visual
two-dimensional
data
long
short-term
memory
avoid
vanishing
gradient
problem
handle
signals
mix
low
high
frequency
components
aiding
large-vocabulary
speech
recognition
text-to-speech
synthesis
photo-real
talking
heads
competitive
networks
generative
adversarial
networks
multiple
networks
varying
structure
compete
tasks
winning
game
deceiving
opponent
authenticity
input
==
network
design
==
neural
architecture
search
nas
uses
machine
learning
automate
ann
design
various
approaches
nas
designed
networks
compare
well
hand-designed
systems
basic
search
algorithm
propose
candidate
model
evaluate
dataset
use
results
feedback
teach
nas
network
available
systems
include
automl
autokeras
design
issues
include
deciding
number
type
connectedness
network
layers
well
size
connection
type
full
pooling
...
hyperparameters
must
also
defined
part
design
learned
governing
matters
many
neurons
layer
learning
rate
step
stride
depth
receptive
field
padding
cnns
etc
==
use
==
using
artificial
neural
networks
requires
understanding
characteristics
choice
model
depends
data
representation
application
overly
complex
models
slow
learning
learning
algorithm
numerous
trade-offs
exist
learning
algorithms
almost
algorithm
work
well
correct
hyperparameters
training
particular
data
set
however
selecting
tuning
algorithm
training
unseen
data
requires
significant
experimentation
robustness
model
cost
function
learning
algorithm
selected
appropriately
resulting
ann
become
robust
ann
capabilities
fall
within
following
broad
categories
function
approximation
regression
analysis
including
time
series
prediction
fitness
approximation
modeling
classification
including
pattern
sequence
recognition
novelty
detection
sequential
decision
making
data
processing
including
filtering
clustering
blind
source
separation
compression
robotics
including
directing
manipulators
prostheses
control
including
computer
numerical
control
==
applications
==
ability
reproduce
model
nonlinear
processes
artificial
neural
networks
found
applications
many
disciplines
application
areas
include
system
identification
control
vehicle
control
trajectory
prediction
process
control
natural
resource
management
quantum
chemistry
general
game
playing
pattern
recognition
radar
systems
face
identification
signal
classification
3d
reconstruction
object
recognition
sequence
recognition
gesture
speech
handwritten
printed
text
recognition
medical
diagnosis
finance
e.g
automated
trading
systems
data
mining
visualization
machine
translation
social
network
filtering
e-mail
spam
filtering
anns
used
diagnose
cancers
including
lung
cancer
prostate
cancer
colorectal
cancer
distinguish
highly
invasive
cancer
cell
lines
less
invasive
lines
using
cell
shape
information
anns
used
accelerate
reliability
analysis
infrastructures
subject
natural
disasters
predict
foundation
settlements
anns
also
used
building
black-box
models
geoscience
hydrology
ocean
modelling
coastal
engineering
geomorphology
anns
employed
cybersecurity
objective
discriminate
legitimate
activities
malicious
ones
example
machine
learning
used
classifying
android
malware
identifying
domains
belonging
threat
actors
detecting
urls
posing
security
risk
research
underway
ann
systems
designed
penetration
testing
detecting
botnets
credit
cards
frauds
network
intrusions
anns
proposed
tool
simulate
properties
many-body
open
quantum
systems
brain
research
anns
studied
short-term
behavior
individual
neurons
dynamics
neural
circuitry
arise
interactions
individual
neurons
behavior
arise
abstract
neural
modules
represent
complete
subsystems
studies
considered
long-and
short-term
plasticity
neural
systems
relation
learning
memory
individual
neuron
system
level
==
theoretical
properties
==
===
computational
power
===
multilayer
perceptron
universal
function
approximator
proven
universal
approximation
theorem
however
proof
constructive
regarding
number
neurons
required
network
topology
weights
learning
parameters
specific
recurrent
architecture
rational-valued
weights
opposed
full
precision
real
number-valued
weights
power
universal
turing
machine
using
finite
number
neurons
standard
linear
connections
use
irrational
values
weights
results
machine
super-turing
power
===
capacity
===
model
's
``
capacity
''
property
corresponds
ability
model
given
function
related
amount
information
stored
network
notion
complexity
two
notions
capacity
known
community
information
capacity
vc
dimension
information
capacity
perceptron
intensively
discussed
sir
david
mackay
's
book
summarizes
work
thomas
cover
capacity
network
standard
neurons
convolutional
derived
four
rules
derive
understanding
neuron
electrical
element
information
capacity
captures
functions
modelable
network
given
data
input
second
notion
vc
dimension
vc
dimension
uses
principles
measure
theory
finds
maximum
capacity
best
possible
circumstances
given
input
data
specific
form
noted
vc
dimension
arbitrary
inputs
half
information
capacity
perceptron
vc
dimension
arbitrary
points
sometimes
referred
memory
capacity
===
convergence
===
models
may
consistently
converge
single
solution
firstly
local
minima
may
exist
depending
cost
function
model
secondly
optimization
method
used
might
guarantee
converge
begins
far
local
minimum
thirdly
sufficiently
large
data
parameters
methods
become
impractical
convergence
behavior
certain
types
ann
architectures
understood
others
width
network
approaches
infinity
ann
resembles
linear
model
thus
ann
follows
convergence
behavior
linear
model
also
another
example
parameters
small
observed
ann
often
fits
target
functions
low
high
frequencies
phenomenon
opposite
behavior
well
studied
iterative
numerical
schemes
jacobi
method
===
generalization
statistics
===
applications
whose
goal
create
system
generalizes
well
unseen
examples
face
possibility
over-training
arises
convoluted
over-specified
systems
network
capacity
significantly
exceeds
needed
free
parameters
two
approaches
address
over-training
first
use
cross-validation
similar
techniques
check
presence
over-training
select
hyperparameters
minimize
generalization
error
second
use
form
regularization
concept
emerges
probabilistic
bayesian
framework
regularization
performed
selecting
larger
prior
probability
simpler
models
also
statistical
learning
theory
goal
minimize
two
quantities
'empirical
risk
'structural
risk
roughly
corresponds
error
training
set
predicted
error
unseen
data
due
overfitting
supervised
neural
networks
use
mean
squared
error
mse
cost
function
use
formal
statistical
methods
determine
confidence
trained
model
mse
validation
set
used
estimate
variance
value
used
calculate
confidence
interval
network
output
assuming
normal
distribution
confidence
analysis
made
way
statistically
valid
long
output
probability
distribution
stays
network
modified
assigning
softmax
activation
function
generalization
logistic
function
output
layer
neural
network
softmax
component
component-based
network
categorical
target
variables
outputs
interpreted
posterior
probabilities
useful
classification
gives
certainty
measure
classifications
softmax
activation
function
e
x
∑
j
1
c
e
x
j
\displaystyle
y_
\frac
e^
x_
\sum
j=1
c
e^
x_
j
==
criticism
==
===
training
===
common
criticism
neural
networks
particularly
robotics
require
much
training
real-world
operation
potential
solutions
include
randomly
shuffling
training
examples
using
numerical
optimization
algorithm
take
large
steps
changing
network
connections
following
example
grouping
examples
so-called
mini-batches
and/or
introducing
recursive
least
squares
algorithm
cmac
===
theory
===
fundamental
objection
anns
sufficiently
reflect
neuronal
function
backpropagation
critical
step
although
mechanism
exists
biological
neural
networks
information
coded
real
neurons
known
sensor
neurons
fire
action
potentials
frequently
sensor
activation
muscle
cells
pull
strongly
associated
motor
neurons
receive
action
potentials
frequently
case
relaying
information
sensor
neuron
motor
neuron
almost
nothing
principles
information
handled
biological
neural
networks
known
central
claim
anns
embody
new
powerful
general
principles
processing
information
unfortunately
principles
ill-defined
often
claimed
emergent
network
allows
simple
statistical
association
basic
function
artificial
neural
networks
described
learning
recognition
alexander
dewdney
commented
result
artificial
neural
networks
``
something-for-nothing
quality
one
imparts
peculiar
aura
laziness
distinct
lack
curiosity
good
computing
systems
human
hand
mind
intervenes
solutions
found
magic
one
seems
learned
anything
''
one
response
dewdney
neural
networks
handle
many
complex
diverse
tasks
ranging
autonomously
flying
aircraft
detecting
credit
card
fraud
mastering
game
go
technology
writer
roger
bridgman
commented
neural
networks
instance
dock
hyped
high
heaven
n't
also
could
create
successful
net
without
understanding
worked
bunch
numbers
captures
behaviour
would
probability
``
opaque
unreadable
table
...
valueless
scientific
resource
''
spite
emphatic
declaration
science
technology
dewdney
seems
pillory
neural
nets
bad
science
devising
trying
good
engineers
unreadable
table
useful
machine
could
read
would
still
well
worth
biological
brains
use
shallow
deep
circuits
reported
brain
anatomy
displaying
wide
variety
invariance
weng
argued
brain
self-wires
largely
according
signal
statistics
therefore
serial
cascade
catch
major
statistical
dependencies
===
hardware
===
large
effective
neural
networks
require
considerable
computing
resources
brain
hardware
tailored
task
processing
signals
graph
neurons
simulating
even
simplified
neuron
von
neumann
architecture
may
consume
vast
amounts
memory
storage
furthermore
designer
often
needs
transmit
signals
many
connections
associated
neurons
–
require
enormous
cpu
power
time
schmidhuber
noted
resurgence
neural
networks
twenty-first
century
largely
attributable
advances
hardware
1991
2015
computing
power
especially
delivered
gpgpus
gpus
increased
around
million-fold
making
standard
backpropagation
algorithm
feasible
training
networks
several
layers
deeper
use
accelerators
fpgas
gpus
reduce
training
times
months
days
neuromorphic
engineering
addresses
hardware
difficulty
directly
constructing
non-von-neumann
chips
directly
implement
neural
networks
circuitry
another
type
chip
optimized
neural
network
processing
called
tensor
processing
unit
tpu
===
practical
counterexamples
===
analyzing
learned
ann
much
easier
analyze
learned
biological
neural
network
furthermore
researchers
involved
exploring
learning
algorithms
neural
networks
gradually
uncovering
general
principles
allow
learning
machine
successful
example
local
vs.
non-local
learning
shallow
vs.
deep
architecture
===
hybrid
approaches
===
advocates
hybrid
models
combining
neural
networks
symbolic
approaches
claim
mixture
better
capture
mechanisms
human
mind
==
gallery
==
==
see
also
==
==
references
==
==
bibliography
==
==
external
links
==
neural
network
zoo
–
compilation
neural
network
types
stilwell
brain
–
mind
field
episode
featuring
experiment
humans
act
individual
neurons
neural
network
classifies
handwritten
digits
https
//en.wikipedia.org/wiki/machine_learning
machine
learning
ml
study
computer
algorithms
improve
automatically
experience
seen
subset
artificial
intelligence
machine
learning
algorithms
build
mathematical
model
based
sample
data
known
``
training
data
''
order
make
predictions
decisions
without
explicitly
programmed
machine
learning
algorithms
used
wide
variety
applications
email
filtering
computer
vision
difficult
infeasible
develop
conventional
algorithms
perform
needed
tasks
machine
learning
closely
related
computational
statistics
focuses
making
predictions
using
computers
study
mathematical
optimization
delivers
methods
theory
application
domains
field
machine
learning
data
mining
related
field
study
focusing
exploratory
data
analysis
unsupervised
learning
application
across
business
problems
machine
learning
also
referred
predictive
analytics
==
overview
==
machine
learning
involves
computers
discovering
perform
tasks
without
explicitly
programmed
early
tasks
humans
assigned
computers
possible
create
algorithms
telling
machine
execute
needed
steps
solve
problem
hand
computer
's
part
learning
needed
advanced
tasks
challenging
human
manually
create
needed
algorithms
practice
turn
effective
help
machine
develop
algorithm
rather
human
programmers
specify
every
needed
step
discipline
machine
learning
employs
various
approaches
help
computers
learn
accomplish
tasks
fully
satisfactory
algorithm
exists
example
cases
vast
numbers
potential
answers
exist
correct
ones
labelled
valid
used
training
data
computer
improve
algorithm
uses
determine
correct
answers
===
machine
learning
approaches
===
early
classifications
machine
learning
approaches
sometimes
divided
three
broad
categories
depending
nature
``
signal
''
``
feedback
''
available
learning
system
supervised
learning
computer
presented
example
inputs
desired
outputs
given
``
teacher
''
goal
learn
general
rule
maps
inputs
outputs
unsupervised
learning
labels
given
learning
algorithm
leaving
find
structure
input
unsupervised
learning
goal
discovering
hidden
patterns
data
means
towards
end
feature
learning
reinforcement
learning
computer
program
interacts
dynamic
environment
must
perform
certain
goal
driving
vehicle
playing
game
opponent
navigates
problem
space
program
provided
feedback
's
analogous
rewards
tries
maximise
approaches
processes
since
developed
n't
fit
neatly
three-fold
categorisation
sometimes
one
used
machine
learning
system
example
topic
modeling
dimensionality
reduction
meta
learning
2020
deep
learning
become
dominant
approach
much
ongoing
work
field
machine
learning
==
history
relationships
fields
==
term
machine
learning
coined
1959
arthur
samuel
american
ibmer
pioneer
field
computer
gaming
artificial
intelligence
representative
book
machine
learning
research
1960s
nilsson
's
book
learning
machines
dealing
mostly
machine
learning
pattern
classification
interest
related
pattern
recognition
continued
1970s
described
duda
hart
1973.
1981
report
given
using
teaching
strategies
neural
network
learns
recognize
40
characters
26
letters
10
digits
4
special
symbols
computer
terminal
tom
m.
mitchell
provided
widely
quoted
formal
definition
algorithms
studied
machine
learning
field
``
computer
program
said
learn
experience
e
respect
class
tasks
performance
measure
p
performance
tasks
measured
p
improves
experience
e.
''
definition
tasks
machine
learning
concerned
offers
fundamentally
operational
definition
rather
defining
field
cognitive
terms
follows
alan
turing
's
proposal
paper
``
computing
machinery
intelligence
''
question
``
machines
think
''
replaced
question
``
machines
thinking
entities
''
===
relation
artificial
intelligence
===
scientific
endeavor
machine
learning
grew
quest
artificial
intelligence
early
days
ai
academic
discipline
researchers
interested
machines
learn
data
attempted
approach
problem
various
symbolic
methods
well
termed
``
neural
networks
''
mostly
perceptrons
models
later
found
reinventions
generalized
linear
models
statistics
probabilistic
reasoning
also
employed
especially
automated
medical
diagnosis
however
increasing
emphasis
logical
knowledge-based
approach
caused
rift
ai
machine
learning
probabilistic
systems
plagued
theoretical
practical
problems
data
acquisition
representation
1980
expert
systems
come
dominate
ai
statistics
favor
work
symbolic/knowledge-based
learning
continue
within
ai
leading
inductive
logic
programming
statistical
line
research
outside
field
ai
proper
pattern
recognition
information
retrieval
neural
networks
research
abandoned
ai
computer
science
around
time
line
continued
outside
ai/cs
field
``
connectionism
''
researchers
disciplines
including
hopfield
rumelhart
hinton
main
success
came
mid-1980s
reinvention
backpropagation
machine
learning
reorganized
separate
field
started
flourish
1990s
field
changed
goal
achieving
artificial
intelligence
tackling
solvable
problems
practical
nature
shifted
focus
away
symbolic
approaches
inherited
ai
toward
methods
models
borrowed
statistics
probability
theory
2019
many
sources
continue
assert
machine
learning
remains
sub
field
ai
yet
practitioners
example
dr
daniel
hulme
teaches
ai
runs
company
operating
field
argues
machine
learning
ai
separate
===
relation
data
mining
===
machine
learning
data
mining
often
employ
methods
overlap
significantly
machine
learning
focuses
prediction
based
known
properties
learned
training
data
data
mining
focuses
discovery
previously
unknown
properties
data
analysis
step
knowledge
discovery
databases
data
mining
uses
many
machine
learning
methods
different
goals
hand
machine
learning
also
employs
data
mining
methods
``
unsupervised
learning
''
preprocessing
step
improve
learner
accuracy
much
confusion
two
research
communities
often
separate
conferences
separate
journals
ecml
pkdd
major
exception
comes
basic
assumptions
work
machine
learning
performance
usually
evaluated
respect
ability
reproduce
known
knowledge
knowledge
discovery
data
mining
kdd
key
task
discovery
previously
unknown
knowledge
evaluated
respect
known
knowledge
uninformed
unsupervised
method
easily
outperformed
supervised
methods
typical
kdd
task
supervised
methods
used
due
unavailability
training
data
===
relation
optimization
===
machine
learning
also
intimate
ties
optimization
many
learning
problems
formulated
minimization
loss
function
training
set
examples
loss
functions
express
discrepancy
predictions
model
trained
actual
problem
instances
example
classification
one
wants
assign
label
instances
models
trained
correctly
predict
pre-assigned
labels
set
examples
difference
two
fields
arises
goal
generalization
optimization
algorithms
minimize
loss
training
set
machine
learning
concerned
minimizing
loss
unseen
samples
===
relation
statistics
===
machine
learning
statistics
closely
related
fields
terms
methods
distinct
principal
goal
statistics
draws
population
inferences
sample
machine
learning
finds
generalizable
predictive
patterns
according
michael
i.
jordan
ideas
machine
learning
methodological
principles
theoretical
tools
long
pre-history
statistics
also
suggested
term
data
science
placeholder
call
overall
field
leo
breiman
distinguished
two
statistical
modeling
paradigms
data
model
algorithmic
model
wherein
``
algorithmic
model
''
means
less
machine
learning
algorithms
like
random
forest
statisticians
adopted
methods
machine
learning
leading
combined
field
call
statistical
learning
==
theory
==
core
objective
learner
generalize
experience
generalization
context
ability
learning
machine
perform
accurately
new
unseen
examples/tasks
experienced
learning
data
set
training
examples
come
generally
unknown
probability
distribution
considered
representative
space
occurrences
learner
build
general
model
space
enables
produce
sufficiently
accurate
predictions
new
cases
computational
analysis
machine
learning
algorithms
performance
branch
theoretical
computer
science
known
computational
learning
theory
training
sets
finite
future
uncertain
learning
theory
usually
yield
guarantees
performance
algorithms
instead
probabilistic
bounds
performance
quite
common
bias–variance
decomposition
one
way
quantify
generalization
error
best
performance
context
generalization
complexity
hypothesis
match
complexity
function
underlying
data
hypothesis
less
complex
function
model
fitted
data
complexity
model
increased
response
training
error
decreases
hypothesis
complex
model
subject
overfitting
generalization
poorer
addition
performance
bounds
learning
theorists
study
time
complexity
feasibility
learning
computational
learning
theory
computation
considered
feasible
done
polynomial
time
two
kinds
time
complexity
results
positive
results
show
certain
class
functions
learned
polynomial
time
negative
results
show
certain
classes
learned
polynomial
time
==
approaches
==
===
types
learning
algorithms
===
types
machine
learning
algorithms
differ
approach
type
data
input
output
type
task
problem
intended
solve
====
supervised
learning
====
supervised
learning
algorithms
build
mathematical
model
set
data
contains
inputs
desired
outputs
data
known
training
data
consists
set
training
examples
training
example
one
inputs
desired
output
also
known
supervisory
signal
mathematical
model
training
example
represented
array
vector
sometimes
called
feature
vector
training
data
represented
matrix
iterative
optimization
objective
function
supervised
learning
algorithms
learn
function
used
predict
output
associated
new
inputs
optimal
function
allow
algorithm
correctly
determine
output
inputs
part
training
data
algorithm
improves
accuracy
outputs
predictions
time
said
learned
perform
task
types
supervised
learning
algorithms
include
active
learning
classification
regression
classification
algorithms
used
outputs
restricted
limited
set
values
regression
algorithms
used
outputs
may
numerical
value
within
range
example
classification
algorithm
filters
emails
input
would
incoming
email
output
would
name
folder
file
email
similarity
learning
area
supervised
machine
learning
closely
related
regression
classification
goal
learn
examples
using
similarity
function
measures
similar
related
two
objects
applications
ranking
recommendation
systems
visual
identity
tracking
face
verification
speaker
verification
====
unsupervised
learning
====
unsupervised
learning
algorithms
take
set
data
contains
inputs
find
structure
data
like
grouping
clustering
data
points
algorithms
therefore
learn
test
data
labeled
classified
categorized
instead
responding
feedback
unsupervised
learning
algorithms
identify
commonalities
data
react
based
presence
absence
commonalities
new
piece
data
central
application
unsupervised
learning
field
density
estimation
statistics
finding
probability
density
function
though
unsupervised
learning
encompasses
domains
involving
summarizing
explaining
data
features
cluster
analysis
assignment
set
observations
subsets
called
clusters
observations
within
cluster
similar
according
one
predesignated
criteria
observations
drawn
different
clusters
dissimilar
different
clustering
techniques
make
different
assumptions
structure
data
often
defined
similarity
metric
evaluated
example
internal
compactness
similarity
members
cluster
separation
difference
clusters
methods
based
estimated
density
graph
connectivity
====
semi-supervised
learning
====
semi-supervised
learning
falls
unsupervised
learning
without
labeled
training
data
supervised
learning
completely
labeled
training
data
training
examples
missing
training
labels
yet
many
machine-learning
researchers
found
unlabeled
data
used
conjunction
small
amount
labeled
data
produce
considerable
improvement
learning
accuracy
weakly
supervised
learning
training
labels
noisy
limited
imprecise
however
labels
often
cheaper
obtain
resulting
larger
effective
training
sets
====
reinforcement
learning
====
reinforcement
learning
area
machine
learning
concerned
software
agents
ought
take
actions
environment
maximize
notion
cumulative
reward
due
generality
field
studied
many
disciplines
game
theory
control
theory
operations
research
information
theory
simulation-based
optimization
multi-agent
systems
swarm
intelligence
statistics
genetic
algorithms
machine
learning
environment
typically
represented
markov
decision
process
mdp
many
reinforcement
learning
algorithms
use
dynamic
programming
techniques
reinforcement
learning
algorithms
assume
knowledge
exact
mathematical
model
mdp
used
exact
models
infeasible
reinforcement
learning
algorithms
used
autonomous
vehicles
learning
play
game
human
opponent
====
self
learning
====
self-learning
machine
learning
paradigm
introduced
1982
along
neural
network
capable
self-learning
named
crossbar
adaptive
array
caa
learning
external
rewards
external
teacher
advices
caa
self-learning
algorithm
computes
crossbar
fashion
decisions
actions
emotions
feelings
consequence
situations
system
driven
interaction
cognition
emotion
self-learning
algorithm
updates
memory
matrix
w
=||w
||
iteration
executes
following
machine
learning
routine
situation
perform
action
receive
consequence
situation
’
compute
emotion
consequence
situation
v
’
update
crossbar
memory
w
’
w
v
’
system
one
input
situation
one
output
action
behavior
a.
neither
separate
reinforcement
input
advice
input
environment
backpropagated
value
secondary
reinforcement
emotion
toward
consequence
situation
caa
exists
two
environments
one
behavioral
environment
behaves
genetic
environment
wherefrom
initially
receives
initial
emotions
situations
encountered
behavioral
environment
receiving
genome
species
vector
genetic
environment
caa
learns
goal
seeking
behavior
environment
contains
desirable
undesirable
situations
====
feature
learning
====
several
learning
algorithms
aim
discovering
better
representations
inputs
provided
training
classic
examples
include
principal
components
analysis
cluster
analysis
feature
learning
algorithms
also
called
representation
learning
algorithms
often
attempt
preserve
information
input
also
transform
way
makes
useful
often
pre-processing
step
performing
classification
predictions
technique
allows
reconstruction
inputs
coming
unknown
data-generating
distribution
necessarily
faithful
configurations
implausible
distribution
replaces
manual
feature
engineering
allows
machine
learn
features
use
perform
specific
task
feature
learning
either
supervised
unsupervised
supervised
feature
learning
features
learned
using
labeled
input
data
examples
include
artificial
neural
networks
multilayer
perceptrons
supervised
dictionary
learning
unsupervised
feature
learning
features
learned
unlabeled
input
data
examples
include
dictionary
learning
independent
component
analysis
autoencoders
matrix
factorization
various
forms
clustering
manifold
learning
algorithms
attempt
constraint
learned
representation
low-dimensional
sparse
coding
algorithms
attempt
constraint
learned
representation
sparse
meaning
mathematical
model
many
zeros
multilinear
subspace
learning
algorithms
aim
learn
low-dimensional
representations
directly
tensor
representations
multidimensional
data
without
reshaping
higher-dimensional
vectors
deep
learning
algorithms
discover
multiple
levels
representation
hierarchy
features
higher-level
abstract
features
defined
terms
generating
lower-level
features
argued
intelligent
machine
one
learns
representation
disentangles
underlying
factors
variation
explain
observed
data
feature
learning
motivated
fact
machine
learning
tasks
classification
often
require
input
mathematically
computationally
convenient
process
however
real-world
data
images
video
sensory
data
yielded
attempts
algorithmically
define
specific
features
alternative
discover
features
representations
examination
without
relying
explicit
algorithms
====
sparse
dictionary
learning
====
sparse
dictionary
learning
feature
learning
method
training
example
represented
linear
combination
basis
functions
assumed
sparse
matrix
method
strongly
np-hard
difficult
solve
approximately
popular
heuristic
method
sparse
dictionary
learning
k-svd
algorithm
sparse
dictionary
learning
applied
several
contexts
classification
problem
determine
class
previously
unseen
training
example
belongs
dictionary
class
already
built
new
training
example
associated
class
best
sparsely
represented
corresponding
dictionary
sparse
dictionary
learning
also
applied
image
de-noising
key
idea
clean
image
patch
sparsely
represented
image
dictionary
noise
====
anomaly
detection
====
data
mining
anomaly
detection
also
known
outlier
detection
identification
rare
items
events
observations
raise
suspicions
differing
significantly
majority
data
typically
anomalous
items
represent
issue
bank
fraud
structural
defect
medical
problems
errors
text
anomalies
referred
outliers
novelties
noise
deviations
exceptions
particular
context
abuse
network
intrusion
detection
interesting
objects
often
rare
objects
unexpected
bursts
activity
pattern
adhere
common
statistical
definition
outlier
rare
object
many
outlier
detection
methods
particular
unsupervised
algorithms
fail
data
unless
aggregated
appropriately
instead
cluster
analysis
algorithm
may
able
detect
micro-clusters
formed
patterns
three
broad
categories
anomaly
detection
techniques
exist
unsupervised
anomaly
detection
techniques
detect
anomalies
unlabeled
test
data
set
assumption
majority
instances
data
set
normal
looking
instances
seem
fit
least
remainder
data
set
supervised
anomaly
detection
techniques
require
data
set
labeled
``
normal
''
``
abnormal
''
involves
training
classifier
key
difference
many
statistical
classification
problems
inherently
unbalanced
nature
outlier
detection
semi-supervised
anomaly
detection
techniques
construct
model
representing
normal
behavior
given
normal
training
data
set
test
likelihood
test
instance
generated
model
====
robot
learning
====
developmental
robotics
robot
learning
algorithms
generate
sequences
learning
experiences
also
known
curriculum
cumulatively
acquire
new
skills
self-guided
exploration
social
interaction
humans
robots
use
guidance
mechanisms
active
learning
maturation
motor
synergies
imitation
====
association
rules
====
association
rule
learning
rule-based
machine
learning
method
discovering
relationships
variables
large
databases
intended
identify
strong
rules
discovered
databases
using
measure
``
interestingness
''
.rule-based
machine
learning
general
term
machine
learning
method
identifies
learns
evolves
``
rules
''
store
manipulate
apply
knowledge
defining
characteristic
rule-based
machine
learning
algorithm
identification
utilization
set
relational
rules
collectively
represent
knowledge
captured
system
contrast
machine
learning
algorithms
commonly
identify
singular
model
universally
applied
instance
order
make
prediction
rule-based
machine
learning
approaches
include
learning
classifier
systems
association
rule
learning
artificial
immune
systems
based
concept
strong
rules
rakesh
agrawal
tomasz
imieliński
arun
swami
introduced
association
rules
discovering
regularities
products
large-scale
transaction
data
recorded
point-of-sale
pos
systems
supermarkets
example
rule
n
n
p
e
⇒
b
u
r
g
e
r
\displaystyle
\mathrm
onions
potatoes
\rightarrow
\mathrm
burger
found
sales
data
supermarket
would
indicate
customer
buys
onions
potatoes
together
likely
also
buy
hamburger
meat
information
used
basis
decisions
marketing
activities
promotional
pricing
product
placements
addition
market
basket
analysis
association
rules
employed
today
application
areas
including
web
usage
mining
intrusion
detection
continuous
production
bioinformatics
contrast
sequence
mining
association
rule
learning
typically
consider
order
items
either
within
transaction
across
transactions
learning
classifier
systems
lcs
family
rule-based
machine
learning
algorithms
combine
discovery
component
typically
genetic
algorithm
learning
component
performing
either
supervised
learning
reinforcement
learning
unsupervised
learning
seek
identify
set
context-dependent
rules
collectively
store
apply
knowledge
piecewise
manner
order
make
predictions
inductive
logic
programming
ilp
approach
rule-learning
using
logic
programming
uniform
representation
input
examples
background
knowledge
hypotheses
given
encoding
known
background
knowledge
set
examples
represented
logical
database
facts
ilp
system
derive
hypothesized
logic
program
entails
positive
negative
examples
inductive
programming
related
field
considers
kind
programming
languages
representing
hypotheses
logic
programming
functional
programs
inductive
logic
programming
particularly
useful
bioinformatics
natural
language
processing
gordon
plotkin
ehud
shapiro
laid
initial
theoretical
foundation
inductive
machine
learning
logical
setting
shapiro
built
first
implementation
model
inference
system
1981
prolog
program
inductively
inferred
logic
programs
positive
negative
examples
term
inductive
refers
philosophical
induction
suggesting
theory
explain
observed
facts
rather
mathematical
induction
proving
property
members
well-ordered
set
===
models
===
performing
machine
learning
involves
creating
model
trained
training
data
process
additional
data
make
predictions
various
types
models
used
researched
machine
learning
systems
====
artificial
neural
networks
====
artificial
neural
networks
anns
connectionist
systems
computing
systems
vaguely
inspired
biological
neural
networks
constitute
animal
brains
systems
``
learn
''
perform
tasks
considering
examples
generally
without
programmed
task-specific
rules
ann
model
based
collection
connected
units
nodes
called
``
artificial
neurons
''
loosely
model
neurons
biological
brain
connection
like
synapses
biological
brain
transmit
information
``
signal
''
one
artificial
neuron
another
artificial
neuron
receives
signal
process
signal
additional
artificial
neurons
connected
common
ann
implementations
signal
connection
artificial
neurons
real
number
output
artificial
neuron
computed
non-linear
function
sum
inputs
connections
artificial
neurons
called
``
edges
''
artificial
neurons
edges
typically
weight
adjusts
learning
proceeds
weight
increases
decreases
strength
signal
connection
artificial
neurons
may
threshold
signal
sent
aggregate
signal
crosses
threshold
typically
artificial
neurons
aggregated
layers
different
layers
may
perform
different
kinds
transformations
inputs
signals
travel
first
layer
input
layer
last
layer
output
layer
possibly
traversing
layers
multiple
times
original
goal
ann
approach
solve
problems
way
human
brain
would
however
time
attention
moved
performing
specific
tasks
leading
deviations
biology
artificial
neural
networks
used
variety
tasks
including
computer
vision
speech
recognition
machine
translation
social
network
filtering
playing
board
video
games
medical
diagnosis
deep
learning
consists
multiple
hidden
layers
artificial
neural
network
approach
tries
model
way
human
brain
processes
light
sound
vision
hearing
successful
applications
deep
learning
computer
vision
speech
recognition
====
decision
trees
====
decision
tree
learning
uses
decision
tree
predictive
model
go
observations
item
represented
branches
conclusions
item
's
target
value
represented
leaves
one
predictive
modeling
approaches
used
statistics
data
mining
machine
learning
tree
models
target
variable
take
discrete
set
values
called
classification
trees
tree
structures
leaves
represent
class
labels
branches
represent
conjunctions
features
lead
class
labels
decision
trees
target
variable
take
continuous
values
typically
real
numbers
called
regression
trees
decision
analysis
decision
tree
used
visually
explicitly
represent
decisions
decision
making
data
mining
decision
tree
describes
data
resulting
classification
tree
input
decision
making
====
support
vector
machines
====
support
vector
machines
svms
also
known
support
vector
networks
set
related
supervised
learning
methods
used
classification
regression
given
set
training
examples
marked
belonging
one
two
categories
svm
training
algorithm
builds
model
predicts
whether
new
example
falls
one
category
svm
training
algorithm
non-probabilistic
binary
linear
classifier
although
methods
platt
scaling
exist
use
svm
probabilistic
classification
setting
addition
performing
linear
classification
svms
efficiently
perform
non-linear
classification
using
called
kernel
trick
implicitly
mapping
inputs
high-dimensional
feature
spaces
====
regression
analysis
====
regression
analysis
encompasses
large
variety
statistical
methods
estimate
relationship
input
variables
associated
features
common
form
linear
regression
single
line
drawn
best
fit
given
data
according
mathematical
criterion
ordinary
least
squares
latter
often
extended
regularization
mathematics
methods
mitigate
overfitting
bias
ridge
regression
dealing
non-linear
problems
go-to
models
include
polynomial
regression
example
used
trendline
fitting
microsoft
excel
logistic
regression
often
used
statistical
classification
even
kernel
regression
introduces
non-linearity
taking
advantage
kernel
trick
implicitly
map
input
variables
higher
dimensional
space
====
bayesian
networks
====
bayesian
network
belief
network
directed
acyclic
graphical
model
probabilistic
graphical
model
represents
set
random
variables
conditional
independence
directed
acyclic
graph
dag
example
bayesian
network
could
represent
probabilistic
relationships
diseases
symptoms
given
symptoms
network
used
compute
probabilities
presence
various
diseases
efficient
algorithms
exist
perform
inference
learning
bayesian
networks
model
sequences
variables
like
speech
signals
protein
sequences
called
dynamic
bayesian
networks
generalizations
bayesian
networks
represent
solve
decision
problems
uncertainty
called
influence
diagrams
====
genetic
algorithms
====
genetic
algorithm
ga
search
algorithm
heuristic
technique
mimics
process
natural
selection
using
methods
mutation
crossover
generate
new
genotypes
hope
finding
good
solutions
given
problem
machine
learning
genetic
algorithms
used
1980s
1990s
conversely
machine
learning
techniques
used
improve
performance
genetic
evolutionary
algorithms
===
training
models
===
usually
machine
learning
models
require
lot
data
order
perform
well
usually
training
machine
learning
model
one
needs
collect
large
representative
sample
data
training
set
data
training
set
varied
corpus
text
collection
images
data
collected
individual
users
service
overfitting
something
watch
training
machine
learning
model
====
federated
learning
====
federated
learning
new
approach
training
machine
learning
models
decentralizes
training
process
allowing
users
privacy
maintained
needing
send
data
centralized
server
also
increases
efficiency
decentralizing
training
process
many
devices
example
gboard
uses
federated
machine
learning
train
search
query
prediction
models
users
mobile
phones
without
send
individual
searches
back
google
==
applications
==
many
applications
machine
learning
including
2006
media-services
provider
netflix
held
first
``
netflix
prize
''
competition
find
program
better
predict
user
preferences
improve
accuracy
existing
cinematch
movie
recommendation
algorithm
least
10
joint
team
made
researchers
labs-research
collaboration
teams
big
chaos
pragmatic
theory
built
ensemble
model
win
grand
prize
2009
1
million
shortly
prize
awarded
netflix
realized
viewers
ratings
best
indicators
viewing
patterns
``
everything
recommendation
''
changed
recommendation
engine
accordingly
2010
wall
street
journal
wrote
firm
rebellion
research
use
machine
learning
predict
financial
crisis
2012
co-founder
sun
microsystems
vinod
khosla
predicted
80
medical
doctors
jobs
would
lost
next
two
decades
automated
machine
learning
medical
diagnostic
software
2014
reported
machine
learning
algorithm
applied
field
art
history
study
fine
art
paintings
may
revealed
previously
unrecognized
influences
among
artists
2019
springer
nature
published
first
research
book
created
using
machine
learning
==
limitations
==
although
machine
learning
transformative
fields
machine-learning
programs
often
fail
deliver
expected
results
reasons
numerous
lack
suitable
data
lack
access
data
data
bias
privacy
problems
badly
chosen
tasks
algorithms
wrong
tools
people
lack
resources
evaluation
problems
2018
self-driving
car
uber
failed
detect
pedestrian
killed
collision
attempts
use
machine
learning
healthcare
ibm
watson
system
failed
deliver
even
years
time
billions
investment
===
bias
===
machine
learning
approaches
particular
suffer
different
data
biases
machine
learning
system
trained
current
customers
may
able
predict
needs
new
customer
groups
represented
training
data
trained
man-made
data
machine
learning
likely
pick
constitutional
unconscious
biases
already
present
society
language
models
learned
data
shown
contain
human-like
biases
machine
learning
systems
used
criminal
risk
assessment
found
biased
black
people
2015
google
photos
would
often
tag
black
people
gorillas
2018
still
well
resolved
google
reportedly
still
using
workaround
remove
gorillas
training
data
thus
able
recognize
real
gorillas
similar
issues
recognizing
non-white
people
found
many
systems
2016
microsoft
tested
chatbot
learned
twitter
quickly
picked
racist
sexist
language
challenges
effective
use
machine
learning
may
take
longer
adopted
domains
concern
fairness
machine
learning
reducing
bias
machine
learning
propelling
use
human
good
increasingly
expressed
artificial
intelligence
scientists
including
fei-fei
li
reminds
engineers
``
’
nothing
artificial
ai
...
’
inspired
people
’
created
people
and—most
importantly—it
impacts
people
powerful
tool
beginning
understand
profound
responsibility.
”
==
model
assessments
==
classification
machine
learning
models
validated
accuracy
estimation
techniques
like
holdout
method
splits
data
training
test
set
conventionally
2/3
training
set
1/3
test
set
designation
evaluates
performance
training
model
test
set
comparison
k-fold-cross-validation
method
randomly
partitions
data
k
subsets
k
experiments
performed
respectively
considering
1
subset
evaluation
remaining
k-1
subsets
training
model
addition
holdout
cross-validation
methods
bootstrap
samples
n
instances
replacement
dataset
used
assess
model
accuracy
addition
overall
accuracy
investigators
frequently
report
sensitivity
specificity
meaning
true
positive
rate
tpr
true
negative
rate
tnr
respectively
similarly
investigators
sometimes
report
false
positive
rate
fpr
well
false
negative
rate
fnr
however
rates
ratios
fail
reveal
numerators
denominators
total
operating
characteristic
toc
effective
method
express
model
's
diagnostic
ability
toc
shows
numerators
denominators
previously
mentioned
rates
thus
toc
provides
information
commonly
used
receiver
operating
characteristic
roc
roc
's
associated
area
curve
auc
==
ethics
==
machine
learning
poses
host
ethical
questions
systems
trained
datasets
collected
biases
may
exhibit
biases
upon
use
algorithmic
bias
thus
digitizing
cultural
prejudices
example
using
job
hiring
data
firm
racist
hiring
policies
may
lead
machine
learning
system
duplicating
bias
scoring
job
applicants
similarity
previous
successful
applicants
responsible
collection
data
documentation
algorithmic
rules
used
system
thus
critical
part
machine
learning
human
languages
contain
biases
machines
trained
language
corpora
necessarily
also
learn
biases
forms
ethical
challenges
related
personal
biases
seen
health
care
concerns
among
health
care
professionals
systems
might
designed
public
's
interest
income-generating
machines
especially
true
united
states
long-standing
ethical
dilemma
improving
health
care
also
increasing
profits
example
algorithms
could
designed
provide
patients
unnecessary
tests
medication
algorithm
's
proprietary
owners
hold
stakes
huge
potential
machine
learning
health
care
provide
professionals
great
tool
diagnose
medicate
even
plan
recovery
paths
patients
happen
personal
biases
mentioned
previously
``
greed
''
biases
addressed
==
software
==
software
suites
containing
variety
machine
learning
algorithms
include
following
===
free
open-source
software
===
===
proprietary
software
free
open-source
editions
===
===
proprietary
software
===
==
journals
==
journal
machine
learning
research
machine
learning
nature
machine
intelligence
neural
computation
==
conferences
==
conference
neural
information
processing
systems
international
conference
machine
learning
==
see
also
==
==
references
==
==
reading
==
==
external
links
==
international
machine
learning
society
mloss
academic
database
open-source
machine
learning
software
machine
learning
crash
course
google
free
course
machine
learning
use
tensorflow
